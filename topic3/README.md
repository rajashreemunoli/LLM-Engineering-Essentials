# Topic 3. Context

**The course is under construction, with new materials appearing regularly.**

## Contents

* **3.1. The concept of RAG** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic3/3.1_the_concept_of_rag.ipynb)

  Check why adding context is a often crucial thing to do in LLM-powered applications. Explore Retrieval Augmented Generation based on web search and examine a Deep Reseach demo.

* **3.2. Database search and vector stores** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic3/3.2_database_search_and_vector_stores.ipynb)
  
  Learn how to augment LLM generation with context from relational and vector databases

* **3.3. Advanced RAG components** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic3/3.3_advanced_rag_components.ipynb)

  Implement two types of two-stage RAG pipelines - one with a reranking step after retrieval and another compining vector and graph databases. Explore Hierarchical Navigable Small World - the nearest neighbour search algorithm used in most of today's vector databases.
