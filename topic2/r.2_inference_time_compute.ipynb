{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9541f68623f47a3b63688031800c044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45fd267b9e2b470c872576b29c4c0f03",
              "IPY_MODEL_a22196074f444ce8a1041d4f1de957ee",
              "IPY_MODEL_174f78be17f9468bb475f8c4879acc4e"
            ],
            "layout": "IPY_MODEL_a8eb3c67e05942aaac802cf14ac26902"
          }
        },
        "45fd267b9e2b470c872576b29c4c0f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e9378e24944bfaa97af667dccfd3a6",
            "placeholder": "​",
            "style": "IPY_MODEL_bf081bba15fe4a0ea7c91c93b35a4975",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a22196074f444ce8a1041d4f1de957ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6be8d373e03481391ff309f07e1bb16",
            "max": 55385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_255dc4b271b440fcb7505352de6d4844",
            "value": 55385
          }
        },
        "174f78be17f9468bb475f8c4879acc4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80725acd6d854d3aba38337bb50ca7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5209cec6e5d149798ca4ff4f4a6a9f92",
            "value": " 55.4k/55.4k [00:00&lt;00:00, 6.41MB/s]"
          }
        },
        "a8eb3c67e05942aaac802cf14ac26902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e9378e24944bfaa97af667dccfd3a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf081bba15fe4a0ea7c91c93b35a4975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6be8d373e03481391ff309f07e1bb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255dc4b271b440fcb7505352de6d4844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80725acd6d854d3aba38337bb50ca7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5209cec6e5d149798ca4ff4f4a6a9f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e5b20b2a51432da46ddf987b65a816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_326ea9fbff1246e19ff13665bec35ed9",
              "IPY_MODEL_ee5447b9e099406dbfbcab8a46df57dd",
              "IPY_MODEL_f73b2965b7f14ec183369462187953b1"
            ],
            "layout": "IPY_MODEL_b7ad40360c2f4c78ab2a8e449b5e587f"
          }
        },
        "326ea9fbff1246e19ff13665bec35ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1478f905f7e140a1b2df33651c06f437",
            "placeholder": "​",
            "style": "IPY_MODEL_c46f93a1e5e64d258e1389355025820a",
            "value": "tokenizer.json: 100%"
          }
        },
        "ee5447b9e099406dbfbcab8a46df57dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba98f01b7e04eacbc040705365db9ae",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2434c25cb834d65b970d5f504a2be8f",
            "value": 17209920
          }
        },
        "f73b2965b7f14ec183369462187953b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1c295a391e4b05a8a9e2df444510df",
            "placeholder": "​",
            "style": "IPY_MODEL_0eea8feb343a4e09b6950b9df302d5b0",
            "value": " 17.2M/17.2M [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "b7ad40360c2f4c78ab2a8e449b5e587f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1478f905f7e140a1b2df33651c06f437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46f93a1e5e64d258e1389355025820a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ba98f01b7e04eacbc040705365db9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2434c25cb834d65b970d5f504a2be8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de1c295a391e4b05a8a9e2df444510df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eea8feb343a4e09b6950b9df302d5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b87f777769bd46aaba333ca7ca398978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0c5099a529d4320995a869680df9b54",
              "IPY_MODEL_d7d1fbd01e5647b1b68a9b29543b8c3d",
              "IPY_MODEL_5c223e07622647d8867ee39afd25b520"
            ],
            "layout": "IPY_MODEL_9273a9d1f5314616a4124bb9cafd5f5e"
          }
        },
        "a0c5099a529d4320995a869680df9b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc85bffa329d410a9875dd7de6e1a1f7",
            "placeholder": "​",
            "style": "IPY_MODEL_4c4a5dc2ae7143d79daadd596e720a7d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d7d1fbd01e5647b1b68a9b29543b8c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e4721be33843738ce2df03f7636f9b",
            "max": 444,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5841cb63c31d45b18e598cf4bc281c3d",
            "value": 444
          }
        },
        "5c223e07622647d8867ee39afd25b520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563624004d6146d3bc5874d23151af29",
            "placeholder": "​",
            "style": "IPY_MODEL_cde388ca649e452db931d3bd1680f622",
            "value": " 444/444 [00:00&lt;00:00, 60.0kB/s]"
          }
        },
        "9273a9d1f5314616a4124bb9cafd5f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc85bffa329d410a9875dd7de6e1a1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4a5dc2ae7143d79daadd596e720a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e4721be33843738ce2df03f7636f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5841cb63c31d45b18e598cf4bc281c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "563624004d6146d3bc5874d23151af29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde388ca649e452db931d3bd1680f622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e8c74eb829c41d9babe09edf33a9e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f330cdea43734efba39bb3d916a20c2b",
              "IPY_MODEL_dcd1aec5f0894ee98bd1886097d1910d",
              "IPY_MODEL_86cbe47e65a145469e9e4007b1ed1883"
            ],
            "layout": "IPY_MODEL_763416e26fd645c596885122fa3e429d"
          }
        },
        "f330cdea43734efba39bb3d916a20c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_992e20773834477ea12b600c9e579e74",
            "placeholder": "​",
            "style": "IPY_MODEL_c98ebf1681334d79bd4f60d34c7568d2",
            "value": "config.json: 100%"
          }
        },
        "dcd1aec5f0894ee98bd1886097d1910d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f01a1fb6960472dba368e1a1998bb12",
            "max": 896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2601c82f73b407987099153293b0fea",
            "value": 896
          }
        },
        "86cbe47e65a145469e9e4007b1ed1883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90f106acc637409989d5d6076aa4dba9",
            "placeholder": "​",
            "style": "IPY_MODEL_37db92fc0b4143ed930768bb267a5dc2",
            "value": " 896/896 [00:00&lt;00:00, 122kB/s]"
          }
        },
        "763416e26fd645c596885122fa3e429d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992e20773834477ea12b600c9e579e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98ebf1681334d79bd4f60d34c7568d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f01a1fb6960472dba368e1a1998bb12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2601c82f73b407987099153293b0fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90f106acc637409989d5d6076aa4dba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37db92fc0b4143ed930768bb267a5dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "906e6e767e864ff68dc25352b128cad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fc853dc50ab48f3aacab4100df0be04",
              "IPY_MODEL_431e685485204f72bd7ba945ac46d2bb",
              "IPY_MODEL_d468face879b48d192c995198ac84622"
            ],
            "layout": "IPY_MODEL_03efa0106bfa4b96a2926e045d32c7b1"
          }
        },
        "5fc853dc50ab48f3aacab4100df0be04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42fa8aeeca304f428ad08ea7be40f6a9",
            "placeholder": "​",
            "style": "IPY_MODEL_32fc206b49f9431b821de4a3b4a5cfaf",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "431e685485204f72bd7ba945ac46d2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b100d7481feb4911b23b54551bbea9be",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c00f4dfcce3042c89798d34a439cb35d",
            "value": 23950
          }
        },
        "d468face879b48d192c995198ac84622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a630d67676b4428ba853a9bb4c15d08",
            "placeholder": "​",
            "style": "IPY_MODEL_8fe821830bd04db990d388bab8d30adc",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 2.77MB/s]"
          }
        },
        "03efa0106bfa4b96a2926e045d32c7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42fa8aeeca304f428ad08ea7be40f6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fc206b49f9431b821de4a3b4a5cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b100d7481feb4911b23b54551bbea9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00f4dfcce3042c89798d34a439cb35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a630d67676b4428ba853a9bb4c15d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe821830bd04db990d388bab8d30adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63f4317a08f4ec9bba057f83296a80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b6af995e925452a9a03c7c7c7d9039a",
              "IPY_MODEL_fcfa370177214516a5e8c879d245b618",
              "IPY_MODEL_5ae242d90926410da3ee80a215362b71"
            ],
            "layout": "IPY_MODEL_70cb6b932b484aa39a237107b3603ed2"
          }
        },
        "0b6af995e925452a9a03c7c7c7d9039a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f18e6fb6381a4c7db56d632b5af768e2",
            "placeholder": "​",
            "style": "IPY_MODEL_578ac9ef20f7414093a619c0a3588fed",
            "value": "Downloading shards: 100%"
          }
        },
        "fcfa370177214516a5e8c879d245b618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ade592d07a147a29d2731e97cd986b6",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6c629bbbe6d48b093a9beb8fd37fdde",
            "value": 4
          }
        },
        "5ae242d90926410da3ee80a215362b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3c0ce63cb049668853cbf7b493e167",
            "placeholder": "​",
            "style": "IPY_MODEL_acd3d02e6f0b4cb390b51cd21e0aefe9",
            "value": " 4/4 [11:07&lt;00:00, 143.39s/it]"
          }
        },
        "70cb6b932b484aa39a237107b3603ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f18e6fb6381a4c7db56d632b5af768e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578ac9ef20f7414093a619c0a3588fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ade592d07a147a29d2731e97cd986b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c629bbbe6d48b093a9beb8fd37fdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a3c0ce63cb049668853cbf7b493e167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd3d02e6f0b4cb390b51cd21e0aefe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dadcb13380bc4f0e94047d75281d729a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe517ba9e1474ffb8f35f650e5636573",
              "IPY_MODEL_999b53ba688b40b987ef02d628d74c24",
              "IPY_MODEL_105bad09865c435ab3b8bb59373f69d7"
            ],
            "layout": "IPY_MODEL_60826be82d48415db7dfb3026660df79"
          }
        },
        "fe517ba9e1474ffb8f35f650e5636573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6dd74328374e15b70d9d9cff22b049",
            "placeholder": "​",
            "style": "IPY_MODEL_0a49be973cc24c48ab25684ede17c6a6",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "999b53ba688b40b987ef02d628d74c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9747d7ea98452f9e3692159ffa6589",
            "max": 4976698672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a498dedde9b4e3a9fb40f7277948b87",
            "value": 4976698672
          }
        },
        "105bad09865c435ab3b8bb59373f69d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eb24284136545fc95e06ef5a8c8bd11",
            "placeholder": "​",
            "style": "IPY_MODEL_bf7003b8ca1b4ec486241273bf7149e7",
            "value": " 4.98G/4.98G [03:29&lt;00:00, 24.0MB/s]"
          }
        },
        "60826be82d48415db7dfb3026660df79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6dd74328374e15b70d9d9cff22b049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a49be973cc24c48ab25684ede17c6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba9747d7ea98452f9e3692159ffa6589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a498dedde9b4e3a9fb40f7277948b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0eb24284136545fc95e06ef5a8c8bd11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7003b8ca1b4ec486241273bf7149e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21604b40da484f7f81eddf008154e836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfcaf553b8f844a89035716c60d9f4a4",
              "IPY_MODEL_6c77d35de2484bb4aa2d015f51920e57",
              "IPY_MODEL_e51f753ab1df4a47b1b610f1d067015a"
            ],
            "layout": "IPY_MODEL_38098cea0ae54abeb4760979bd1538ce"
          }
        },
        "dfcaf553b8f844a89035716c60d9f4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd6901da37d40fd9f6ea27dbb6ed3bb",
            "placeholder": "​",
            "style": "IPY_MODEL_b6e5edcc401548e1bdaa29ce57d0649b",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "6c77d35de2484bb4aa2d015f51920e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f3155fe295422897b49ca0434b7fa2",
            "max": 4999802720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb250ceed5154caa87e073a7b39d7ec2",
            "value": 4999802720
          }
        },
        "e51f753ab1df4a47b1b610f1d067015a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1688f9957ab40bd8ba2f05378b6608c",
            "placeholder": "​",
            "style": "IPY_MODEL_94de96b1e672406484f919551d9c88b1",
            "value": " 5.00G/5.00G [03:24&lt;00:00, 24.1MB/s]"
          }
        },
        "38098cea0ae54abeb4760979bd1538ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd6901da37d40fd9f6ea27dbb6ed3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e5edcc401548e1bdaa29ce57d0649b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f3155fe295422897b49ca0434b7fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb250ceed5154caa87e073a7b39d7ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1688f9957ab40bd8ba2f05378b6608c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94de96b1e672406484f919551d9c88b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "626e5c1fa8ef4fc3ba3155493ccddc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_018a1ad4db014aeea338e76b5df1f1e4",
              "IPY_MODEL_b0c9f1f4be884085858be44f0a0b2567",
              "IPY_MODEL_52a4d1a3c8174d52902a846f0f27fb3c"
            ],
            "layout": "IPY_MODEL_9aa14ef1f8004f958802aab8fc12289b"
          }
        },
        "018a1ad4db014aeea338e76b5df1f1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e83ab72de3ef4636afa0008ef6fdc383",
            "placeholder": "​",
            "style": "IPY_MODEL_747f96dbbf4240d9b776e6d8337d1276",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        },
        "b0c9f1f4be884085858be44f0a0b2567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f0a18a69274f41be50108c8fa9aab0",
            "max": 4915916176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dac398e0d6c0412da8b8ab293c0e597f",
            "value": 4915916176
          }
        },
        "52a4d1a3c8174d52902a846f0f27fb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e7c421224b4c06968f35dbec8b3288",
            "placeholder": "​",
            "style": "IPY_MODEL_e153c87702ca4865a4589f3ddba1233b",
            "value": " 4.92G/4.92G [03:24&lt;00:00, 24.1MB/s]"
          }
        },
        "9aa14ef1f8004f958802aab8fc12289b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e83ab72de3ef4636afa0008ef6fdc383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747f96dbbf4240d9b776e6d8337d1276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f0a18a69274f41be50108c8fa9aab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac398e0d6c0412da8b8ab293c0e597f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8e7c421224b4c06968f35dbec8b3288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e153c87702ca4865a4589f3ddba1233b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8894b85fd6a4e6db5082142b19c35b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ead4b423f13471b83952d2fd9ee7c35",
              "IPY_MODEL_bead09bdb4504e9bb2780ceebf8be9d4",
              "IPY_MODEL_c663126fb549412a9520d26446f0e092"
            ],
            "layout": "IPY_MODEL_eca35a88341048e4a752c01234882d1b"
          }
        },
        "1ead4b423f13471b83952d2fd9ee7c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e30fc16f674874a6d7b0be2088f213",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6f128206b74e39940da05405810100",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "bead09bdb4504e9bb2780ceebf8be9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9c91244b114c83be987e2f36f24c60",
            "max": 1168138808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef03031acab545968e3a718ed79749ee",
            "value": 1168138808
          }
        },
        "c663126fb549412a9520d26446f0e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a04a051851748468d12a6d7944752ff",
            "placeholder": "​",
            "style": "IPY_MODEL_142ba229d9734f918c1415bc34d6ab0d",
            "value": " 1.17G/1.17G [00:46&lt;00:00, 24.4MB/s]"
          }
        },
        "eca35a88341048e4a752c01234882d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e30fc16f674874a6d7b0be2088f213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6f128206b74e39940da05405810100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c9c91244b114c83be987e2f36f24c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef03031acab545968e3a718ed79749ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a04a051851748468d12a6d7944752ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142ba229d9734f918c1415bc34d6ab0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f3b352b2144bc7a8e33ef3e4047571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_100fd4c5a3264311a215d5a2d79fd137",
              "IPY_MODEL_3d07db1bf08341a3a11d2a46697a2713",
              "IPY_MODEL_eaf4919df6c3455a80622a592ff8c6ca"
            ],
            "layout": "IPY_MODEL_c610bdcb4ead4dd984c561fcb941de53"
          }
        },
        "100fd4c5a3264311a215d5a2d79fd137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f6795dba3d4d538ae370123d1d8fff",
            "placeholder": "​",
            "style": "IPY_MODEL_b7549d348f5648a1af548f2d2f4551af",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3d07db1bf08341a3a11d2a46697a2713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ffaaa047d584a94903c9223ebfb3de4",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dfb596ed4bd449a80aecee3d5248d71",
            "value": 4
          }
        },
        "eaf4919df6c3455a80622a592ff8c6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d1a818ada44b3bb2d36355a4f42c7f",
            "placeholder": "​",
            "style": "IPY_MODEL_bd20878caacf4ac78a4433506e68c34e",
            "value": " 4/4 [00:09&lt;00:00,  2.01s/it]"
          }
        },
        "c610bdcb4ead4dd984c561fcb941de53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f6795dba3d4d538ae370123d1d8fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7549d348f5648a1af548f2d2f4551af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ffaaa047d584a94903c9223ebfb3de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfb596ed4bd449a80aecee3d5248d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54d1a818ada44b3bb2d36355a4f42c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd20878caacf4ac78a4433506e68c34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30ec7745648348cea3e5f797434347c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_530384b312674eac9b32780c10d977e4",
              "IPY_MODEL_dfbb8e90d45f43b7860818b5b823de88",
              "IPY_MODEL_679ed51171984388870b6a90986188ae"
            ],
            "layout": "IPY_MODEL_fdecad77bdf745e69acf5117b8159ca0"
          }
        },
        "530384b312674eac9b32780c10d977e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b602f5e2096044e9aeac6bc170393de7",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8d52bce37649dbbb838465110e8748",
            "value": "generation_config.json: 100%"
          }
        },
        "dfbb8e90d45f43b7860818b5b823de88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab118ab763bd4823bb8f460b1a4f5469",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c0f859e896c4a31a2ce6589e13fb2d3",
            "value": 184
          }
        },
        "679ed51171984388870b6a90986188ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd19d24c2f44a03afacd7b9e7dd3650",
            "placeholder": "​",
            "style": "IPY_MODEL_89b69c60c8d24e11b9e71a877f00b820",
            "value": " 184/184 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "fdecad77bdf745e69acf5117b8159ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b602f5e2096044e9aeac6bc170393de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8d52bce37649dbbb838465110e8748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab118ab763bd4823bb8f460b1a4f5469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0f859e896c4a31a2ce6589e13fb2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bd19d24c2f44a03afacd7b9e7dd3650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b69c60c8d24e11b9e71a877f00b820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [  
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic2/r.2_inference_time_compute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Engineering Essentials by Nebius Academy\n",
        "\n",
        "Course github: [link](https://github.com/Nebius-Academy/LLM-Engineering-Essentials/tree/main)\n",
        "\n",
        "The course is in development now, with more materials coming soon. [Subscribe to stay updated](https://academy.nebius.com/llm-engineering-essentials/update/)\n",
        "\n",
        "# R.2. Inference-time compute"
      ],
      "metadata": {
        "id": "Vm506vpf9u9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we understand that the success of reasoning in math can be partly attributed to sheer computation, it introduces a trade-off between compute and quality. This raises an important question: **Given a certain amount of inference-time compute per question, how can we allocate it optimally?**\n",
        "\n",
        "If we only have enough computational resources for a single LLM query, there's not much to consider. We just run it and hope for the best. But what if we can query an LLM 10 times for one user's request? Or even 1000 times? What if we're as reckless as OpenAI that [spent $10k+ **per task** when they tested **o3** in the ARC-AGI prize](https://arcprize.org/blog/oai-o3-pub-breakthrough).\n",
        "\n",
        "In this notebook, we'll discuss how to use **inference-time compute** wisely through thoughtful orchestration.\n",
        "\n",
        "# Parallel vs sequential orchestration\n",
        "\n",
        "Before the recent breakthroughs in non-linear reasoning, there were several ways to \"bloat\" the compute. Let's start by discussing two of the most straightforward options (see the illustration below), and then move to more intricate ones.\n",
        "\n",
        "- **Parallel**: Running $N$ identical queries in parallel with **non-zero temperature**, then aggregating the results. For example, we might choose the final answer using a majority vote (this strategy is quite confusingly called **Self-consistency**). A higher temperature ensures the outputs differ enough; it's like having $N$ independent experts, each offering their own opinion. With enough experts, the truth could be uncovered from the variety of answers.\n",
        "\n",
        "  In the practice section, we implemented **self-consistency** for you.\n",
        "\n",
        "  This approach is similar to **ensembling** in classical machine learning: a number of sufficiently different models is likely to outperform any individual model. It's not surprising that self-consistency is rather popular due to its power ans simplicity (compared to the other approaches we'll be discussing further).\n",
        "\n",
        "- **Sequential**: Making an LLM revise its solution repeatedly in an \"unsupervised\" manner, simply prompting it to correct its previous response. The tricky part is that [LLMs often aren't very good at self-correction](https://arxiv.org/pdf/2310.01798). So, you’d likely need to fine-tune the LLM for this task. First, though, you'd need to gather a dataset, which is a real challenge. No surprise that few people attempt this.\n",
        "\n",
        "  <details>\n",
        "  <summary>How would you collect data to fine-tune an LLM for self-correction? Click here if you're curious.</summary>\n",
        "  I’ll share a method from [this paper](https://arxiv.org/pdf/2408.03314). The authors:\n",
        "\n",
        "  * Sampled 64 responses in parallel at a higher temperature.\n",
        "  * Paired each correct solution with up to four incorrect ones to create multi-turn self-correction data.\n",
        "  * Used a character edit distance metric to prioritize selecting incorrect solutions closely related to the correct solution. This is a somewhat naive method for determining if one solution is an edit of another, but it worked!\n",
        "  </details>\n",
        "\n",
        "\n",
        "* Finally, if you’ve mastered both approaches, you can combine them into a **hybrid strategy**: self-consistency over a series of rewriting sequences!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=17NfFNgMoWliod4rw3t9W4MGZBwYgiKbC\" width=600 />\n",
        "</center>\n",
        "\n",
        "Image source: [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/pdf/2408.03314) by Google DeepMind, which is a very insightful paper on the topic of inference-time compute.\n",
        "\n",
        "But to truly understand what's going on in this image, we need to take the next step: **checking the solution, not just the answer**."
      ],
      "metadata": {
        "id": "PUfKZIzG8MxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Reward Model (PRM)\n",
        "\n",
        "I used to teach math a lot, and I strongly believe that it’s important to check not only the final answer but also the entire solution. Even a completely wrong solution can sometimes lead to the correct answer, as shown in the following example. When trying to simplify the fraction \\(\\frac{15}{95}\\), why not just cancel out the 5’s from both the numerator and the denominator? Wouldn’t that give the correct answer?\n",
        "\n",
        "$$\\frac{1\\color{red}{5}}{9\\color{red}{5}} = \\frac15$$\n",
        "\n",
        "Let's look at another example with a multi-step solution:\n",
        "\n",
        "**Problem**: Find the maximal root of the equation $\\frac{x^3 - x^2}{x - 1} = 3x - 2$.\n",
        "\n",
        "**Solution**:\n",
        "\n",
        "1) First, let's factor the numerator on the left-hand side: $x^3 - x^2 = x^2(x - 1)$.\n",
        "\n",
        "2) Now we can cancel the $x - 1$ terms, simplifying the equation to $x^2 = 3 - 2x$.\n",
        "\n",
        "3) Moving everything to one side, we get $x^2 - 3x + 2 = 0$.\n",
        "\n",
        "4) This equation has roots at $x = 1$ and $x = 2$.\n",
        "\n",
        "5) Therefore, the maximal root is $\\boxed{2}$.\n",
        "\n",
        "**A grave mistake in the solution** was canceling out $x - 1$ without considering that it can’t be zero. $x = 1$ cannot be a valid root of the original equation, because substituting $x = 1$ results in $\\frac00$ on the left-hand side. However, the final answer is still correct, because we don’t need to consider $x = 1$ in this context.\n",
        "\n",
        "Note that both Llama-3.1-8B and Llama-3.1-70B fall into this trap, while Llama-3.1-405B correctly acknowledges that $x = 1$ cannot be a solution. Without checking the solution, we wouldn't understand where the problem lies.\n",
        "\n",
        "There have been various attempts to rate solutions as a whole (**Outcome Reward Models**, **ORM**) or for each partial step (**Process Reward Models**, **PRM**). PRMs are trickier, more exciting, and potentially more powerful, so let's discuss them in slightly more detail."
      ],
      "metadata": {
        "id": "r0P54Dp8zP0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to define solution steps?\n",
        "\n",
        "There's no simple answer to this question. In the example above, the solution is neatly divided into stages, but LLMs don't always do this. It can also be useful to split solutions by `\"\\n\\n\"` (end of paragraph), but LaTeX equations displayed on their own lines can cause issues with that. For example, see the solution to the same problem provided by Llama-3.1-405B below; nothing good will happen if you just split it by paragraphs.\n",
        "\n",
        "<details>\n",
        "<summary>Click to see the Llama's solution</summary>\n",
        "\n",
        "To find the maximal root of the equation, we first need to simplify it.\n",
        "\n",
        "The given equation is $\\frac{x^3 - x^2}{x - 1} = 3x - 2$.\n",
        "\n",
        "We can factor the numerator as $x^2(x - 1)$.\n",
        "\n",
        "So, the equation becomes $\\frac{x^2(x - 1)}{x - 1} = 3x - 2$.\n",
        "\n",
        "Now, we can cancel out the $(x - 1)$ terms:\n",
        "\n",
        "$x^2 = 3x - 2$\n",
        "\n",
        "Rearranging the equation to form a quadratic equation:\n",
        "\n",
        "$x^2 - 3x + 2 = 0$\n",
        "\n",
        "Factoring the quadratic equation:\n",
        "\n",
        "$(x - 2)(x - 1) = 0$\n",
        "\n",
        "Solving for $x$, we get:\n",
        "\n",
        "$x = 1$ or $x = 2$\n",
        "\n",
        "However, the original equation is undefined when $x = 1$, so we exclude this solution.\n",
        "\n",
        "Therefore, the maximal root of the equation is $x = 2$.\n",
        "\n",
        "</details>\n",
        "\n",
        "So, generally, if you want to use a PRM, it's better to specifically prompt your LLM with something like `Split your solution into individual logical steps and keep each step in one line.`"
      ],
      "metadata": {
        "id": "YP9Jy5TkEaPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the task\n",
        "\n",
        "A PRM scores not just individual steps, but **partial solutions**, like this:\n",
        "\n",
        "| Partial solution         | Value |\n",
        "|---------------|-------|\n",
        "| **Step 1**        | 0.98  |\n",
        "| **Steps 1+2**     | 0.76  |\n",
        "| **Steps 1+2+3**   | 0.21  |\n",
        "| **Steps 1+2+3+4** | 0.29  |\n",
        "\n",
        "That's more logical, because an individual step only makes sense given what was before in the solution.\n",
        "\n",
        "It's reasonable to consider Process Reward Modeling task as binary classification (\"good\"/\"bad\"), which naturally results in predicting a score between 0 and 1 (\"class probabilities\"). As we'll see, we may actually have class probability estimates as targets.\n",
        "\n",
        "An LLM may be fine tuned into a Process Reward Model, for example, by teaching it to answer to good partial solutions with a token `\"+\"` and for bad ones with `\"-\"`. (Or, more generally, to predict `+` with a probability of class \"good\" and `-` with the probability of class \"bad\".)\n",
        "\n",
        "We'll try an LLM tuned to be a PRM in the practice part.\n",
        "\n",
        "**Note**. Of course, an LLM can also be used as a PRM without any fine tuning, in an **LLM-as-a-Judge** mode. For that, you'd need to prompt it to reason about the potential of each partial solution and to give a score, preferrably on a small discrete scale (like 1-5). Though tempting, this approach is not without caveats:\n",
        "\n",
        "* We put too much hope on LLMs' ability to judge reasoning, thought it's their ability to reason we want to improve or score in the first place.\n",
        "* Generally, you'd take a powerful model as an LLM-as-a-Judge scorer, while you can fine tune a smaller model to be a decent PRM. If you only need a scorer to evaluate something once, that may be ok, but if you want to further use it for steering generation at inference, that might be an issue."
      ],
      "metadata": {
        "id": "c-KLtSR7ILXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Where to get PRM training data?\n",
        "\n",
        "This is one of those situations where acquiring data is a tough task. There is no ready-made dataset available, and human labeling would be terribly expensive. (Also, human-generated labels for partial solutions are likely to be poorly calibrated.)\n",
        "\n",
        "A more viable approach is, non-suprisingly, an unsupervised one, based on  running **Monte Carlo rollouts** from each step in the solution. It was suggested in the [Math-Shepherd](https://arxiv.org/pdf/2312.08935) paper and it works like this:\n",
        "\n",
        "* To score a partial solution, generate a large number $N$ of its continuations and check how many of them arrive at the correct answer. (Luckily, most math datasets contain correct answers.) The ratio of valid continuations to $N$ will be the score. It seems to be a good estimate of the \"probability that this partial solution is good\".\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-FnTNw1GV9FMu1k4hKnNTjHZCjGlkq-1\" width=600 />\n",
        "</center>\n",
        "\n",
        "You'll find the code in the practice part of the notebook.\n",
        "\n",
        "**A word of caution**. The ability of the PRM to detect math and logical errors depends on whether those errors in the training data affect the answers. For example, if the training dataset contains only the problem above, where canceling $x-1$ does not influence the answer, the PRM won't learn that cancellations should be performed responsibly. However, if the PRM training dataset includes the problem of finding **all** the roots of $\\frac{x^3 - x^2}{x - 1} = 3x - 2$, it may teach the PRM something about cancellations."
      ],
      "metadata": {
        "id": "PaXkWF4HHH6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRM applications and caveats\n",
        "\n",
        "There are several ways we could use a PRM:\n",
        "\n",
        "* As a reward model for further LLM fine tuning. For example, the [Math-Shepherd](https://arxiv.org/pdf/2312.08935) paper demonstrates that RLHF with a PRM trained for math problems may improve the LLM's math capabilities.\n",
        "* As an alternative to major voting in **Self-consistency**. Indeed, major voting only chooses the most popular answer, but disregards the solution quality. Choosing a solution with the max PRM score may result in more correct outputs. This is exactly what was used in the [DeepMind paper](https://arxiv.org/pdf/2408.03314) we mentioned earlier and from which we borrowed the already familiar picture.\n",
        "\n",
        "  <center>\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=17NfFNgMoWliod4rw3t9W4MGZBwYgiKbC\" width=600 />\n",
        "  </center>\n",
        "\n",
        "  There are several ways of scoring an entire solution with a PRM.\n",
        "  \n",
        "  * Score each partial solution (step 1, steps 1+2, steps 1+2+3,...) and then agregate the scores.\n",
        "  * Just score the whole solution without bothering about its prefixes.\n",
        "  \n",
        "  There's evidence that the second approach works well enough. It's worth noting though, that PRMs, which are trained to score partial solutions, are more accurate than ORMs (Outcome Reward Models), which are trained to score only full solutions.\n",
        "\n",
        "* In sequential rewriting settings, instead of picking the final rewrite, we can use PRM to score every solution in a chain and pick the best scoring one.\n",
        "\n",
        "* Finally, we can use PRM on intermediate steps to steer the generation. And that's what we'll discuss next!\n",
        "\n",
        "Although cool, PRMs have their own issues. They are not totally reliable, and, even worse, they don't transfer too well between different models. You should definitely be careful when scoring solutions by DeepSeek R1 using a PRM trained on solutions generated by Mistral."
      ],
      "metadata": {
        "id": "4swDSEs2PR-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ORM as a PRM\n",
        "\n",
        "In some situations we have an **ORM** (**Outcome Reward Model**), which scores only complete solutions, instead of a PRM. For example, in code generation, a set of tests or other automatically verified requirements may serve the role of an ORM.\n",
        "\n",
        "In such cases, you can use **lookahead** to score partial solutions. The idea won't be new for you:\n",
        "\n",
        "* For a given partial solution, generate a number of full continuations (**rollouts**).\n",
        "* Score each of the continuations and average their score. This will give you the partial solution's score.\n",
        "\n",
        "**Note**. Lookahead search isn't only good for simulating a Process Reward Model with an Outcome Reward Model. Even if you have a PRM, it's sometimes useful to score a partial solution by\n",
        "\n",
        "- generating several steps ahead,\n",
        "- and then scoring this longer partial solution.\n",
        "\n",
        "Moreover, you can use several lookaheads; this may potentially give you a more reliable reward value.\n",
        "\n",
        "**Note**. Sometimes your ORM is just a deterministic check. For example, in the coding task, where automatic tests may be run once there is a full solution. Of course, in this case lookahead search is a great way of scoring partial solutions."
      ],
      "metadata": {
        "id": "AQbKlIJup6zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRM-guided generation and orchestration of non-linear reasoning\n",
        "\n",
        "As we've mentioned before, humans solve problems in a non-linear way - exploring different solution paths, discarding some, and focusing more on others. Self-consistency is a rough analogy of this process - exploring multiple independent thought trajectories - but a rather coarse one.\n",
        "\n",
        "Before LLMs learned to perform non-linear reasoning on their own, various approaches emerged to orchestrate it. In this section, we'll discuss several of them."
      ],
      "metadata": {
        "id": "etGHOdieYMTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree of Thoughts and Beam Search\n",
        "\n",
        "Three of Thoughts, first introduced in [the eponymous paper](https://arxiv.org/pdf/2305.10601) is a rather straightforward implementation of nonlinear generation. The rough idea is to explore a tree of potential solutions, where each vertex is a \"thought\" (a solution step), with Breadth-First Search (BFS) or Depths-First Search (DFS).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16J6w1QdzkX81zm10H1hKetdwvhHKOlz_\" width=600 />\n",
        "\n",
        "[Source](https://arxiv.org/pdf/2305.10601)\n",
        "</center>\n",
        "\n",
        "For a Three of Thoughts algorithm to take shape, we need to choose:\n",
        "\n",
        "* The potential **tree structure**: **max number of branches** at each vertex, **max depth**.\n",
        "* **The way we sample next \"thoughts\"**. Basically, we either make several parallel queries for the LLM to \"generate a next logical step\", or ask it to \"generate several next logical step options\" in one prompt.\n",
        "\n",
        "  The latter approach may be useful for avoiding duplication when there are not too many options present (thing of something like finding shortest route in a graph). Otherwise, I'd go for parallel queries.\n",
        "\n",
        "* How we decide which paths to explore further and which to abandon. For that, you need a way of **scoring** a vertex (a state) or a partial solution that led to it. The original Tree of Thoughts paper used LLM-as-a-Judge (which was well-motivated by the specific tasks they considered), but for most tasks a trained **Process Reward Model** would be a reasonable choice.\n",
        "\n",
        "  Specific PRM-based criteria may be used to determine which branches are hopeless and to prioritize high-potential ones.\n",
        "\n",
        "  A special case of Tree of Thoughts is **Beam Search**, a variation of Breadth-First Search, that keeps at most $B$ (**beam size**) vertices at each level. If $B=2$, it works as follows:\n",
        "\n",
        "  * To begin, 2 first step options are generated.\n",
        "  \n",
        "  * During each of the following interations, 2 next steps are generated for each of the 2 intermediate solutions we have.\n",
        "\n",
        "  * 2 of them, the top-scoring ones, are passed to the next iteration.\n",
        "    \n",
        "  In some variations 4 first steps are generated initially, with 2 top-scoring ones taken for further generation.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1y3io1RqfqyIKcfu7kxRIiZKNKGMXtt9P\" width=500 />\n",
        "</center>\n",
        "\n",
        "In the practice part, we'll implement beam search."
      ],
      "metadata": {
        "id": "-j1whhzou-fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beyond Tree of Thoughts\n",
        "\n",
        "Even more elaborate orchestration efforts emerged in 2023 and 2024, like [Graph of Thoughts](https://arxiv.org/pdf/2308.09687) or [Algorithm of Thoughts](https://arxiv.org/pdf/2308.10379). Another interesting example of a guided tree-based generation strategy is **Monte Carlo Tree Search** (**MCTS**) which we'll discuss in the next notebook. However, these approaches are costly and complicated, and from this point of view they tend to fall behind simply using larger LLMs or LLMs with native non-linear reasoning like OpenAI's o1 and DeepSeek R1. Still, it's interesting to check these approaches and to ponder how they resonate with what happens in R1 and similar models.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WZWjI7aY3Vu0zEsAO8u7R73iwsC6KJeq\" width=600 />\n",
        "\n",
        "[Source](https://arxiv.org/pdf/2308.09687)\n",
        "</center>"
      ],
      "metadata": {
        "id": "lr60Fk3W6h60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical guidelines and inference scaling laws\n",
        "\n",
        "With such an exciting choice of approaches, how can we choose the best one? To start with, we need to understand our **inference budget**, that is the amount of money (or, simplifying this, inference calls) we can spend on processing one query. With the inference budget in mind, we can try choosing\n",
        "\n",
        "* **The LLM we want to use**: which size tier, non-linear reasoning capabilities, etc.\n",
        "* **How to stretch the inference budget**: techniques like self-consistency, beam search, and more.\n",
        "\n",
        "  For example, if our budget allows for $N$ LLM calls per query, we can leverage self-consistency with $N$ parallel calls.\n",
        "\n",
        "  <details>\n",
        "  <summary>Check a very rough comparison of beam search vs self-consistency, if you're curious.</summary>\n",
        "  \n",
        "  Assume that the beam size is $B$, each solution consists of $D$ thoughts, with $T$ tokens each, and the problem consists of $P$ tokens. Also, it will be reasonable to estimate that processing of an input token costs $\\$c$, while generating one output token costs $\\$3c$ (that's more or less true for most APIs). Now, with beam search:\n",
        "\n",
        "  * The first step will cost us $B\\cdot(cP + 3cT)$,\n",
        "  * The second step will cost $B\\cdot([cP + cT] + 3cT)$ (the prompts are now problem + first thought),\n",
        "  * The third step will cost $B\\cdot([cP + 2cT] + 3cT)$ (the prompts are now problem + first thought + second thought),\n",
        "  * ...\n",
        "  * The last, $D$-th step will cost $B\\cdot([cP + (D-1)\\cdot cT] + 3cT)$\n",
        "\n",
        "  Totally, this gives\n",
        "  $$Bc\\cdot\\left(DP + T + 2T + \\ldots + (D-1)T + 3T \\right)=\n",
        "  Bc\\cdot\\left(DP + \\left[\\frac12D(D-1) + 3\\right]T \\right)$$\n",
        "\n",
        "  For self-consistency with $B$ parallel queries, we need $B$ calls with $P$ input tokens and $DT$ output tokens, which results in the cost\n",
        "  $$B\\cdot(cP + 3cDT) = Bc\\cdot(P + 3DT)$$\n",
        "  Note that we didn't count $BD$ PRM calls here!\n",
        "  \n",
        "  Typically, beam search will be more expensive than self-consistency, but now we also see that, due to beam search's cost being quadratic in $D$ (solution length in \"thoughts\"), for long solutions beam search will be staggeringly more expensive.\n",
        "\n",
        "  </details>\n",
        "\n",
        "Some key considerations are:\n",
        "\n",
        "* **Larger models vs. smarter strategies**\n",
        "  Upgrading to a more powerful LLM (e.g., **Llama-3.1-405B** instead of **Llama-3.1-8B**) can provide a major boost in quality, but at a steep cost. In some cases, a smaller LLM combined with self-consistency or a more advanced strategy may outperform the larger model at a lower cost.\n",
        "\n",
        "  However, with growing amoung of inference-time budget, a larger LLM, straightforwardly queried, may eventually become a more favourable choice than a tricky, bug-prone orchestration.\n",
        "  \n",
        "  We'll explore this trade-off in the practical section.\n",
        "\n",
        "* **Trade-offs in PRM-guided generation**\n",
        "  PRM-guided, tree-based generation is costly and more complex to set up. (And good PRMs aren't just lying around!) If you're looking for a starting point, self-consistency is a solid choice.\n",
        "\n",
        "  The [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/pdf/2408.03314) paper presents several experiments aimed at identifying **inference scaling laws** - the patterns of how efficiency evolves as inference budgets change.\n",
        "\n",
        "  The results below are for the [MATH benchmark](https://huggingface.co/datasets/nlile/hendrycks-MATH-benchmark).\n",
        "\n",
        "  * For smaller inference budgets, beam search consistently outperforms other approaches (as long as there's enough compute to run it).\n",
        "  * For larger inference budgets, another method takes the lead: generating multiple solutions in parallel and selecting the best one based on the top PRM score.\n",
        "\n",
        "  Of course, there's no guarantee that these results will generalize to all LLMs and datasets. However, they strongly suggest that even with a large inference budget, you don't necessarily need highly complex strategies to optimize performance.\n",
        "\n",
        "  <center>\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1Bh81Ycx-2H0676F7MTpnRhGYFMg8QMyo\" width=600 />\n",
        "  </center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7D2fy9Dl-aJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ready for more?\n",
        "\n",
        "This notebook is part of the larger free course — **LLM Engineering Essentials** — where you’ll go even further in your learning and build a service for creating smart, human-like NPCs.\n",
        "\n",
        "🎓 New materials are coming soon. Click the link below to subscribe for updates and make sure you don’t miss anything:\n",
        "\n",
        "[Stay updated](https://academy.nebius.com/llm-engineering-essentials/update/)"
      ],
      "metadata": {
        "id": "_mxtZR9OnEpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice session\n",
        "\n",
        "We have ambitious plans for this practice session. We will:\n",
        "\n",
        "* Practice balancing the inference budget between using large LLMs and leveraging complex orchestration strategies with smaller LLMs.\n",
        "* Implement Beam Search using both model-based and confidence-based PRMs.\n",
        "\n",
        "If you encounter any difficulties or simply want to see our solutions, feel free to check the [Solutions notebook](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic2/r.2_inference_time_compute_solutions.ipynb)."
      ],
      "metadata": {
        "id": "8o9CAgcHehks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting ready"
      ],
      "metadata": {
        "id": "mcm2WOgK8JpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "WqCgRtIRIcN3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "with open(\"nebius_api_key\", \"r\") as file:\n",
        "    nebius_api_key = file.read().strip()\n",
        "\n",
        "os.environ[\"NEBIUS_API_KEY\"] = nebius_api_key"
      ],
      "metadata": {
        "id": "NRpRGdl5IdJZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be calling APIs quite often in this notebook, so let's define a shortcut fuction to avoid repeating all the code:"
      ],
      "metadata": {
        "id": "8ElsBJ68uacB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "def prettify_string(text, max_line_length=80):\n",
        "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
        "\n",
        "    Args:\n",
        "        text: The string to print.\n",
        "        max_line_length: The maximum length of each line.\n",
        "    \"\"\"\n",
        "\n",
        "    output_lines = []\n",
        "    lines = text.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        current_line = \"\"\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
        "                current_line += word + \" \"\n",
        "            else:\n",
        "                output_lines.append(current_line.strip())\n",
        "                current_line = word + \" \"\n",
        "        output_lines.append(current_line.strip())  # Append the last line\n",
        "    return \"\\n\".join(output_lines)\n",
        "\n",
        "def answer_with_llm(prompt: str,\n",
        "                    system_prompt=\"You are a helpful assistant\",\n",
        "                    max_tokens=512,\n",
        "                    client=nebius_client,\n",
        "                    model=llama_8b_model,\n",
        "                    prettify=True,\n",
        "                    temperature=None) -> str:\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    if system_prompt:\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            }\n",
        "        )\n",
        "\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    if prettify:\n",
        "        return prettify_string(completion.choices[0].message.content)\n",
        "    else:\n",
        "        return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "YTlC-5omIVOO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice, part 1. Larger models vs smarter strategies: Classifying dialogue roles with CoT and Self-Consistency\n",
        "\n",
        "In this task, we'll work with the [DialogRE benchmark](https://github.com/nlpdata/dialogre) and classify roles in dialogs using Llama models and Nebius AI Studio.\n",
        "\n",
        "Let's start by loading the dataset."
      ],
      "metadata": {
        "id": "E3r-hJxVweIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('dialogre_dev.json', 'r') as f:\n",
        "    dialog_data_raw = json.load(f)"
      ],
      "metadata": {
        "id": "5G2QcVqJk1UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to look at the data."
      ],
      "metadata": {
        "id": "ePkPRnnXxImi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(dialog_data_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az0O5hcUpzbb",
        "outputId": "545f2c77-3b89-4cd1-e5c0-f466edf4ed2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "358"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialog_data_raw[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGTbtR10rJPz",
        "outputId": "fb0cb3e5-ac9e-4d43-8b84-76785fc096e4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Speaker 1: Hey!',\n",
              "  'Speaker 2: Hey.',\n",
              "  \"Speaker 3: Hey, man. What's up?\",\n",
              "  \"Speaker 1: Maybe you can tell me. My agent would like to know why I didn't show up at the audition I didn't know I had today. The first good thing she gets me in weeks. How could you not give me the message?!\",\n",
              "  \"Speaker 3: Well, I'll tell ya I do enjoy guilt, but, ah, it wasn't me.\",\n",
              "  'Speaker 2: Yes, it was! It was him! Uh huh! Okay, it was me!',\n",
              "  'Speaker 1: How is it you?',\n",
              "  \"Speaker 2: Well, it was just, it was all so crazy, you know. I mean, Chandler was in the closet, counting to 10, and he was up to 7 and I hadn't found a place to hide yet. I-I-I meant to tell you, and I wrote it all down on my hand. See, all of it.\",\n",
              "  \"Speaker 1: Yep, that's my audition.\",\n",
              "  'Speaker 4: See, now this is why I keep notepads everywhere.',\n",
              "  \"Speaker 2: Yep, and that's why we don't invite you to play.\",\n",
              "  'Speaker 5: What is the great tragedy here? You go get yourself another appointment.',\n",
              "  'Speaker 1: Well, Estelle tried, you know. The casting director told her that I missed my chance.',\n",
              "  \"Speaker 2: That is unfair. I'll call her and tell her it was totally my fault.\",\n",
              "  \"Speaker 1: Pheebs, you can't do that. The casting director doesn't talk to friends, she only talks to agents.\",\n",
              "  'Speaker 2: What a sad little life she must lead. Okay, ooh.',\n",
              "  'Speaker 1: What, what are you doing? What are you doing?',\n",
              "  \"Speaker 2: No, no, no, I know, I know, ooh. 'Hi, this is Katelynn, from Phoebe Buffay's office. Um, is um, Ann there for Phoebe, she'll know what it's about.'\",\n",
              "  'Speaker 1: Hang up, hang up.',\n",
              "  \"Speaker 2: 'Annie! Hi. Listen we got a problem with Joey Tribbiani, apparently he missed his audition. Who did you speak to in my office? Estelle, no, I don't know what I'm going to do with her. No. All right, so your husband leaves and burns down the apartment, the world does not stop.'\",\n",
              "  'Speaker 3: Is anybody else scared?',\n",
              "  \"Speaker 2: 'Right, well look, um, if Joey loses this audition, that is it for Estelle. I don't care! Annie you are a doll, what time can you see him?' I need a pen.\",\n",
              "  'Speaker 3: Get the woman a pad! Get the woman a pad! A pad! A pad!',\n",
              "  'Speaker 4: Oh, now you want a pad.'],\n",
              " [{'y': 'casting director',\n",
              "   'x': 'Ann',\n",
              "   'rid': [29],\n",
              "   'r': ['per:title'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'STRING'},\n",
              "  {'y': 'Annie',\n",
              "   'x': 'Ann',\n",
              "   'rid': [30],\n",
              "   'r': ['per:alternate_names'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'agent',\n",
              "   'x': 'Estelle',\n",
              "   'rid': [29],\n",
              "   'r': ['per:title'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'STRING'},\n",
              "  {'y': 'Speaker 1',\n",
              "   'x': 'Estelle',\n",
              "   'rid': [7],\n",
              "   'r': ['per:client'],\n",
              "   't': ['agent'],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'Katelynn',\n",
              "   'x': 'Speaker 2',\n",
              "   'rid': [30],\n",
              "   'r': ['per:alternate_names'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'Pheebs',\n",
              "   'x': 'Speaker 2',\n",
              "   'rid': [30],\n",
              "   'r': ['per:alternate_names'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'Speaker 1',\n",
              "   'x': 'Speaker 2',\n",
              "   'rid': [9],\n",
              "   'r': ['per:friends'],\n",
              "   't': ['friends'],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'Phoebe Buffay',\n",
              "   'x': 'Speaker 2',\n",
              "   'rid': [30],\n",
              "   'r': ['per:alternate_names'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'casting director',\n",
              "   'x': 'Annie',\n",
              "   'rid': [29],\n",
              "   'r': ['per:title'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'STRING'},\n",
              "  {'y': 'man',\n",
              "   'x': 'Speaker 3',\n",
              "   'rid': [37],\n",
              "   'r': ['unanswerable'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'STRING'},\n",
              "  {'y': 'man',\n",
              "   'x': 'Speaker 1',\n",
              "   'rid': [30],\n",
              "   'r': ['per:alternate_names'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'STRING'},\n",
              "  {'y': 'Speaker 2',\n",
              "   'x': 'Speaker 1',\n",
              "   'rid': [9],\n",
              "   'r': ['per:friends'],\n",
              "   't': ['friends'],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'},\n",
              "  {'y': 'Joey Tribbiani',\n",
              "   'x': 'Speaker 1',\n",
              "   'rid': [30],\n",
              "   'r': ['per:alternate_names'],\n",
              "   't': [''],\n",
              "   'x_type': 'PER',\n",
              "   'y_type': 'PER'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, many different character roles are labeled for every dialog.\n",
        "\n",
        "Here is the list of all roles:"
      ],
      "metadata": {
        "id": "5cTuF37NxMWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_relations = []\n",
        "for dialog in dialog_data_raw:\n",
        "    for relation in dialog[1]:\n",
        "        for individual_relation in relation['r']:\n",
        "            if not individual_relation in all_relations:\n",
        "                all_relations.append(individual_relation)\n",
        "all_relations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIZKSCiQpedG",
        "outputId": "bd633f5b-77fe-4604-a2e1-05bef848c009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['per:title',\n",
              " 'per:alternate_names',\n",
              " 'per:client',\n",
              " 'per:friends',\n",
              " 'unanswerable',\n",
              " 'per:spouse',\n",
              " 'per:children',\n",
              " 'per:parents',\n",
              " 'per:age',\n",
              " 'per:siblings',\n",
              " 'per:roommate',\n",
              " 'per:negative_impression',\n",
              " 'per:pet',\n",
              " 'per:positive_impression',\n",
              " 'per:girl/boyfriend',\n",
              " 'org:employees_or_members',\n",
              " 'per:employee_or_member_of',\n",
              " 'per:dates',\n",
              " 'per:boss',\n",
              " 'per:subordinate',\n",
              " 'per:other_family',\n",
              " 'org:students',\n",
              " 'per:major',\n",
              " 'per:schools_attended',\n",
              " 'per:origin',\n",
              " 'gpe:visitors_of_place',\n",
              " 'per:visited_place',\n",
              " 'per:alumni',\n",
              " 'per:works',\n",
              " 'per:place_of_residence',\n",
              " 'gpe:residents_of_place',\n",
              " 'per:place_of_work',\n",
              " 'per:date_of_birth',\n",
              " 'per:acquaintance',\n",
              " 'per:neighbor',\n",
              " 'gpe:births_in_place',\n",
              " 'per:place_of_birth']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't want to overcomplicate the task, so we'll stick to simpler and more frequent roles. We'll also exclude `per:alternate_names`, because it's too adundant in the dataset and it would affect class balancing too much."
      ],
      "metadata": {
        "id": "mhSwSYUaxT07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_relations = [\n",
        "    'per:friends', 'per:spouse', 'per:children', 'per:parents',\n",
        "    'per:siblings', 'per:girl/boyfriend', 'per:boss', 'per:subordinate'\n",
        "]"
      ],
      "metadata": {
        "id": "5BlD8YlZqL8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll select only dialogs that contain at least one of the chosen relationship statuses."
      ],
      "metadata": {
        "id": "pn0czT7NZR6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dialog_data = []\n",
        "for dialog in dialog_data_raw:\n",
        "    current_dialog = dialog[0]\n",
        "    current_relations = []\n",
        "    for relation in dialog[1]:\n",
        "        if relation['r'][0] in our_relations:\n",
        "            current_relations.append({\n",
        "                'x': relation['x'],\n",
        "                'y': relation['y'],\n",
        "                'r': relation['r'][0]\n",
        "            })\n",
        "    if len(current_relations) > 0:\n",
        "        dialog_data.append([current_dialog, current_relations])"
      ],
      "metadata": {
        "id": "ZI4bBhfWqtp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dialog_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVOFNT81rYw-",
        "outputId": "6aef25a5-948e-463d-ccbc-df75ff9aecd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialog_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsmW12oyrcCx",
        "outputId": "a66116fd-b3f7-45ce-a88c-81a46598a139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Speaker 1, Speaker 2: Hi',\n",
              "  'Speaker 3: Hi! Hey mom.',\n",
              "  'Speaker 4: This is such a great party! 35 years. Very impressive, do you guys have any pearls of wisdom?',\n",
              "  'Speaker 2: Jack?',\n",
              "  'Speaker 1: Why would you serve food on such a sharp stick?',\n",
              "  'Speaker 3: That’s a good question, dad. That’s a good question…',\n",
              "  'Speaker 4: Hmmm….'],\n",
              " [{'x': 'Speaker 1', 'y': 'Speaker 2', 'r': 'per:spouse'},\n",
              "  {'x': 'Speaker 1', 'y': 'Speaker 3', 'r': 'per:children'},\n",
              "  {'x': 'Speaker 2', 'y': 'Speaker 1', 'r': 'per:spouse'},\n",
              "  {'x': 'Speaker 2', 'y': 'Speaker 3', 'r': 'per:children'},\n",
              "  {'x': 'Jack', 'y': 'Speaker 3', 'r': 'per:children'},\n",
              "  {'x': 'Speaker 3', 'y': 'Speaker 2', 'r': 'per:parents'},\n",
              "  {'x': 'Speaker 3', 'y': 'Speaker 1', 'r': 'per:parents'},\n",
              "  {'x': 'Speaker 3', 'y': 'Jack', 'r': 'per:parents'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To further simplify the task, for each dialog we'll select only one role to predict. We'll use random sampling, but **we'll fix the random seed** to make the selection procedure reproducible. And to save time and money, we'll only take 50 first dialogues from the `dev` set."
      ],
      "metadata": {
        "id": "mPY3PS2FxZP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(28)\n",
        "dialog_data_short = [[dialog, np.random.choice(relations)] for dialog, relations in dialog_data[:50]]"
      ],
      "metadata": {
        "id": "4d1_v0BvrrNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialog_data_short[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmPyshacswcP",
        "outputId": "d198f329-5628-42d7-cdd9-77aaa1913ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Speaker 1, Speaker 2: Hi',\n",
              "  'Speaker 3: Hi! Hey mom.',\n",
              "  'Speaker 4: This is such a great party! 35 years. Very impressive, do you guys have any pearls of wisdom?',\n",
              "  'Speaker 2: Jack?',\n",
              "  'Speaker 1: Why would you serve food on such a sharp stick?',\n",
              "  'Speaker 3: That’s a good question, dad. That’s a good question…',\n",
              "  'Speaker 4: Hmmm….'],\n",
              " {'x': 'Speaker 1', 'y': 'Speaker 3', 'r': 'per:children'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verdicts_true = [relations['r'] for _, relations in dialog_data_short]"
      ],
      "metadata": {
        "id": "iCb35mrt3NZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ML tasks it's always important to look at the target label distribution. In our case it's not balanced: there are much more friends and girl/boyfriends than other roles. We won't take it into the account for now, but in a real-life Data Science problem, we'd try to adjust our metrics to take class imbalance into account."
      ],
      "metadata": {
        "id": "h_xwkLtOxmUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "relations_counter = Counter(verdicts_true)\n",
        "\n",
        "relations_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LLkoKYsYuXt",
        "outputId": "e76c0c37-aa04-4acb-ad8b-304ee779d4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'per:friends': 11,\n",
              "         'per:children': 3,\n",
              "         'per:parents': 4,\n",
              "         'per:siblings': 6,\n",
              "         'per:spouse': 3,\n",
              "         'per:girl/boyfriend': 16,\n",
              "         'per:boss': 5,\n",
              "         'per:subordinate': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take 1: A large model with a simple CoT strategy\n",
        "\n",
        "To start, we'll use Llama-3.1-405B with a straighforward CoT + programmed answer parsing strategy.\n",
        "\n",
        "We could have used an LLM chain with the second model extracting the answer, but it shouldn't be difficult just parse it. The only non-trivial thing we introduce at the parsing stage comes from the observation that sometimes LLMs predict `boyfriend` or `girlfriend` instead of `girl/boyfriend`. So, we just manually map `boyfriend` or `girlfriend` to `girl/boyfriend`."
      ],
      "metadata": {
        "id": "SJUF5oA6s8lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationClassifier():\n",
        "    def __init__(self, client, model):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.raw_classes = [\"friends\", \"spouse\", \"children\", \"parents\",\n",
        "                            \"siblings\", \"girl/boyfriend\", \"boss\", \"subordinate\"]\n",
        "\n",
        "    def predict(self, dialog, character_x, character_y, verbose=False):\n",
        "        reasoning_completion = self.client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"You are an expert in Natural Nanguage Understanding.\n",
        "You are gived a dialog and two characters participating or mentioned in this dialog.\n",
        "You need to predict relationships between these characters choosing from the following list:\n",
        "- friends\n",
        "- spouse\n",
        "- children\n",
        "- parents\n",
        "- siblings\n",
        "- girl/boyfriend\n",
        "- boss\n",
        "- subordinate\n",
        "Provide a clear reasoning justifying your choice. Then write your final answer after #VERDICT:\n",
        "Now, take a deep breath and work out this problem step by step. If you do well, I'll tip you 200$.\n",
        "\n",
        "DIALOG: {dialog}\n",
        "\n",
        "FIRST CHARACTER: {character_x}\n",
        "\n",
        "SECOND CHARACTER: {character_y}\n",
        "\n",
        "REASONING:\"\"\"\n",
        "                }\n",
        "            ],\n",
        "            model=self.model,\n",
        "            )\n",
        "        reasoning = reasoning_completion.choices[0].message.content\n",
        "\n",
        "        # Extract whatever is after #VERDICT:\n",
        "        re_match = re.search(r\"#VERDICT(.*)\", reasoning, re.DOTALL)\n",
        "        if re_match:\n",
        "            extracted_answer = re_match.group(1).strip()\n",
        "        else:\n",
        "            extracted_answer = \"Failed to parse\"\n",
        "\n",
        "        # Parse the answer\n",
        "        verdict = extracted_answer.lower().strip(\"'\\\".; \")\n",
        "        if verdict == \"boyfriend\" or verdict == \"girlfriend\":\n",
        "            verdict = \"girl/boyfriend\"\n",
        "        if verdict in self.raw_classes:\n",
        "            verdict = \"per:\" + verdict\n",
        "        else:\n",
        "            verdict = \"per:failed\"\n",
        "\n",
        "        if verbose:\n",
        "            return {\n",
        "                \"reasoning_completion\": reasoning_completion,\n",
        "                \"extracted_answer\": extracted_answer,\n",
        "                \"verdict\": verdict\n",
        "            }\n",
        "        else:\n",
        "            return verdict"
      ],
      "metadata": {
        "id": "KrqQpYFruIYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "classifier_llama_405b = RelationClassifierChain(\n",
        "    client=client, model=\"meta-llama/Meta-Llama-3.1-405B-Instruct\"\n",
        "    )"
      ],
      "metadata": {
        "id": "5OStYwWyuIYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's good to start logging the results"
      ],
      "metadata": {
        "id": "7Yinf3RNuIYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completions_log = dict() # Raw completions\n",
        "verdicts_log = dict() # Final verdicts"
      ],
      "metadata": {
        "id": "zim7LWvFuIYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The tqdm library allows to create progress bars for cycles\n",
        "from tqdm import tqdm\n",
        "\n",
        "current_configuration = \"Meta-Llama-3.1-405B-Instruct, no enhancements\"\n",
        "results = []\n",
        "\n",
        "# If you're short in compute, try for dialog_data_short[:10]\n",
        "for dialog, relations in tqdm(dialog_data_short):\n",
        "    results.append(classifier_llama_405b.predict(dialog, relations['x'], relations['y'], verbose=True))\n",
        "\n",
        "completions_log[current_configuration] = results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442c84f0-bea5-49d8-ce57-86a3fadfc479",
        "id": "PBVR38n5uIYx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [08:53<00:00, 10.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the results:"
      ],
      "metadata": {
        "id": "i13-Tjo7uIYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfff34ff-549b-43f2-9878-d367a145b845",
        "id": "QJ0vcnp2uIYx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'reasoning_completion': ChatCompletion(id='chat-96edbd003f1c489f93aa2d75dd2a958f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To determine the relationship between Speaker 1 and Speaker 3, let\\'s analyze the dialog provided.\\n\\n1. Speaker 3 greets with \"Hi! Hey mom.\" Initially, this could suggest that Speaker 3 is addressing their mother, but since Speaker 3 later addresses Speaker 1 as \"dad,\" we can infer that Speaker 3 was addressing their mother who is not participating in this part of the conversation or is Speaker 4. It doesn\\'t impact our main relationship in question.\\n\\n2. The critical clue is when Speaker 3 says, \"That’s a good question, dad. That’s a good question…\" This line directly addresses Speaker 1 as \"dad,\" which indicates a parental relationship.\\n\\nGiven these points, the relationship between Speaker 1 and Speaker 3 can be classified under the \\'per:parents\\' category since Speaker 1 is the parent (father) of Speaker 3.\\n\\nVERDICT: \\'per:parents\\'', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)], created=1731333358, model='meta-llama/Meta-Llama-3.1-405B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=193, prompt_tokens=289, total_tokens=482, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None),\n",
              " 'extraction_completion': ChatCompletion(id='chat-7bf1a74704a24436ab08bfa79b883790', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"'per:parents'\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)], created=1731333364, model='meta-llama/Meta-Llama-3.1-405B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=6, prompt_tokens=314, total_tokens=320, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None),\n",
              " 'verdict': \"'per:parents'\"}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's check the percentage of cases when we failed to parse the verdict:"
      ],
      "metadata": {
        "id": "O9mD2rnidYHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verdicts = [result[\"verdict\"] for result in results]\n",
        "print(sum([verdict == \"per:failed\" for verdict in verdicts]) / len(verdicts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62dc10a-c264-43a4-b698-ae61c9a43aef",
        "id": "t5GKTBS0uIYy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['per:friends', \"'per:parents'\", \"'per:parents'\", 'per:friends', 'per:spouse', 'per:friends', 'per:girl/boyfriend', \"'per:boss'\", 'per:spouse', 'per:girl/boyfriend', 'per:boss', 'per:girl/boyfriend', 'per:subordinate', 'per:girl/boyfriend', 'per:girl/boyfriend', 'per:boss', 'per:friends', 'per:girl/boyfriend', 'per:spouse', 'per:friends', 'per:friends', 'per:girl/boyfriend', 'per:girl/boyfriend', 'per:friends', 'per:girl/boyfriend', 'per:siblings', 'per:boss', 'per:friends', 'per:parents', 'per:girl/boyfriend', 'per:friends', 'per:friends', 'per:spouse', 'per:friends', 'per:siblings', \"'per:girl/boyfriend'\", \"'per:siblings'\", 'per:girl/boyfriend', 'per:parents', 'per:friends', 'per:friends', 'per:girl/boyfriend', 'per:siblings', 'per:girl/boyfriend', 'per:girl/boyfriend', 'per:parents', 'per:children', 'per:boss', 'per:subordinate', 'per:friends']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's check the accuracy of our predictions."
      ],
      "metadata": {
        "id": "QUs5ryKquIYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    return sum(np.array(y_true) == np.array(y_pred)) / len(y_true)\n",
        "\n",
        "accuracy_score(verdicts_true, verdicts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf3d595-9ce5-4cad-ba9c-ec889ddbeb28",
        "id": "04DLp75NuIYy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not bad for a start!"
      ],
      "metadata": {
        "id": "Z2vVSd-kuIYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take 2: A smaller LLM\n",
        "\n",
        "Let's see how a smaller model **Llama-3.1-8B** will cope with this task!"
      ],
      "metadata": {
        "id": "Zxb5AMVduIYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_llama_8b = RelationClassifierChain(\n",
        "    client=client, model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "    )\n",
        "\n",
        "current_configuration = \"Meta-Llama-3.1-8B-Instruct, no enhancement\"\n",
        "results = []\n",
        "# do it for patient_visits[-10:] to save time\n",
        "for dialog, relations in tqdm(dialog_data_short):\n",
        "    results.append(classifier_llama_8b.predict(dialog, relations['x'], relations['y'], verbose=True))\n",
        "\n",
        "completions_log[current_configuration] = results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c974f3f4-2b25-478c-8a1c-7b89026d7f12",
        "id": "C8e_7vrCuIYy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [04:13<00:00,  5.07s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[-3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f282ad2-ccb9-414e-a86a-1cb1c7c8908a",
        "id": "h7ccwuXguIYy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'reasoning_completion': ChatCompletion(id='chat-934dd724a2814e11847567c550d93a25', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Based on the dialog, I predict the relationship between Mr. Kostelick and Speaker 2 as \\'per:boss\\'.\\n\\nReasoning:\\n\\n1. Speaker 2 is mentioned as needing to stop by Mr. Kostelick\\'s office at the end of the day (Speaker 3\\'s line).\\n2. Mr. Kostelick is referred to as \"Mr. Kostelick wants you to stop by his office at the end of the day\" (Speaker 3\\'s line), indicating that Speaker 2 reports to or is supervised by Mr. Kostelick.\\n3. Speaker 2 is also defensive when accused of being involved in a prank memo, and mentions \"Mr. Kostelick\" in the context of work (Speaker 2\\'s lines \"If this is about those prank memos, I had nothing to do with them.\").\\n4. Speaker 7, Chandler, mentions that Speaker 2 has been at the office for five years, implying a long-standing employment relationship.\\n5. Speaker 2\\'s lines suggest that they have a certain level of familiarity with Mr. Kostelick\\'s office and working style, including the fact that someone like \"big Al\" (presumably a reference to a previous manager) was able to make them a job offer.\\n\\nGiven these points, it appears that Mr. Kostelick is Speaker 2\\'s supervisor or boss.\\n\\nVERDICT:\\n\\n\\'per:boss\\'', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)], created=1731334121, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=289, prompt_tokens=488, total_tokens=777, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None),\n",
              " 'extraction_completion': ChatCompletion(id='chat-2cbb52b2c68b4e038966ba6b0fc81ac1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"'per:boss'\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)], created=1731334126, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=6, prompt_tokens=385, total_tokens=391, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None),\n",
              " 'verdict': \"'per:boss'\"}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how many verdicts are parsed wrongly:"
      ],
      "metadata": {
        "id": "fDHpnaL-knp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verdicts = [result[\"verdict\"] for result in results]\n",
        "print(sum([verdict == \"per:failed\" for verdict in verdicts]) / len(verdicts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2c4e84-f6c8-4378-d37e-ac0d68714f81",
        "id": "bStA382nuIYy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'per:client'\", \"'per:parents'.\", '**per:parents**', \"'per:friends'\", 'Ross is the boyfriend or partner of Speaker 1.', \"['per:friends']\", 'per:spouse', 'per:boss', \"'per:girl/boyfriend'\", \"'per:friends'\", \"['per:subordinate']\", 'per:girl/boyfriend', \"['per:boss']\", 'per:spouse', \"['per:friends']\", '\\'per:girl/boyfriend\\' is unlikely, but... \\'per:girl/boyfriend\\' is not the final verdict\\n\\nWAIT, MY DIAGNOSTIC IS \\'per:girl/boyfriend\\' UNLIKELY BUT...\\n\\nMy diagnosis is \\'per:girl/boyfriend\\' unlikely, but the final verdict is likely one of the remaining options which is:\\n\\n\\'per:girl/boyfriend\\' is unlikely but another option is more likely\\n\\nThe final verdict is:\\n\\'per:girl/boyfriend\\' is unlikely but another option is more likely.\\n\\nHowever, there is more text that indicates the verdict.\\n\\n* \\'per:girl/boyfriend\\'- unlikely, as the dialogue does not suggest a romantic relationship.\\n* \\'per:subordinate\\' - unlikely, as Speaker 2 seems to be on an equal level or possibly higher than Speaker 1.\\n\\nHowever, \\'per:girl/boyfriend is unlikely\\' but another option is more likely. Considering other possibilities, the most likely relationship is as follows.\\n\\nBased on the text, the actual verdict is:\\n\\n\\'per:friens\\' is possible but not the best match, \\'per:boss\\', is possible but eliminated, \\'per:girl/boyfriend\\' is unlikely but \\'per:siblings\\', \\'per:children\\', \\'per:parents\\' are all unlikely and we are also not considering \\'per:subordinate\\' because the relationship is likely more equal or possibly higher.\\n\\nHowever, what we are left with is \\'per:friend\\', that could potentially be correct given the use of \"Pheebs\" and getting scolded for getting involved with assistants.\\n\\nGiven the information above the verdict is:\\n\\n\\'per:friends\\'', '**per:friends**', \"'per:girl/boyfriend'\", 'per:spouse', 'per:friends', \"'per:friends'\", \"**'per:girl/boyfriend'**\", 'per:girl/boyfriend', \"'per:friends'\", '*per:spouse, per:girl/boyfriend*', \"'per:siblings'\", \"'per:boss'\", '**per:friends**', 'per:children between Susan and Ben.', \"'per:girl/boyfriend'\", \"['per:friends']\", \"I'd be happy to help!\\n\\n'per:friends'\", 'The verdict is: Mattress King and Janice are spousal figures.', \"'per:friends'\", \"['per:siblings']\", '**per:girl/boyfriend**', \"'per:friends'\", \"['per:spouse', 'per:former partner']\", \"'per:parents'\", \"['per:friends']\", '**per:friends**', 'per:girl/boyfriend', 'per:children', 'per:girl/boyfriend', \"['per:girl/boyfriend']\", 'per:parents', 'per:friends', \"'per:boss'\", \"['per:boss', 'per:subordinate']\", 'per:friends']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And, finally, the accuracy:"
      ],
      "metadata": {
        "id": "tFO_l1SZktQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(verdicts_true, verdicts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a931e941-5a33-46d2-81f3-f873d5288e49",
        "id": "-e0Y2ck0uIYy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's worse.\n",
        "\n",
        "But let's also check how many of the raw verdict are in the correct format:"
      ],
      "metadata": {
        "id": "JVTyIZ6wuIYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take 3: A smaller LLM with Self-consistency"
      ],
      "metadata": {
        "id": "j_YI_XmShnVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM's generations will change from iteration to iteration, and the answers may change as well. And actually the accuracy of the above algorithm is unstable."
      ],
      "metadata": {
        "id": "07dMhqjphnVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll leverage this as another possibility of improving the quality. There's a reason to suppose that even though one reasoning may be false, several attempts of the LLM at reasoning may reveal the truth.\n",
        "\n",
        "The most popular approach is called **Self Consistency**. It works as follows:\n",
        "\n",
        "- Generate several (say, 5 or 7) reasoning paths, extract answer from each of them,\n",
        "- Choose the most frequent option.\n",
        "\n",
        "This is like a majority vote of several identical LLMs."
      ],
      "metadata": {
        "id": "3OtOc1wLhnVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dialog, relations = dialog_data_short[5]\n",
        "for _ in range(5):\n",
        "    print(classifier_few_shot.predict(\n",
        "        dialog, relations['x'], relations['y'], verbose=True\n",
        "        )[\"reasoning_completion\"].choices[0].message.content)\n",
        "    print(\"\\n###\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f792b73e-5d99-4a40-e8b1-677360c6e118",
        "id": "AsepWWMVhnVN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker 2 and Speaker 3 are mentioned in the dialog as being in a relationship, as evidenced by Speaker 3's use of the term \"my husband\" to refer to Speaker 2 (at the end of the dialog). This implies that Speaker 2 and Speaker 3 are married.\n",
            "\n",
            "Therefore, based on the relationship options provided, I choose:\n",
            "\n",
            "VERDICT: 'per:spouse'\n",
            "\n",
            "###\n",
            "\n",
            "After analyzing the dialog, I can infer the following relationships between the characters:\n",
            "\n",
            "* Speaker 2 (Monica) is a close friend of Speaker 3 (Rachel), as they share a warm and intimate conversation, with Speaker 3 involving Speaker 2 in her personal life (treating Speaker 3 to a solo where she discusses how to communicate with Phoebe).\n",
            "* Speaker 3 (Rachel) and Speaker 4 (Phoebe) are also close friends, as they are part of the same social circle and share inside jokes (\"What about Mike? Alright, well, let's just gag him and handcuff him and force him down the aisle. I can just see it: 'Mike, do you take Phoebe...\").\n",
            "* Speaker 2 (Monica) seems to be aware of Speaker 3's (Rachel) direct connection with the proposal to Speaker 4 (Phoebe), since the Speaker 2 decides to share the information with Speaker 3.\n",
            "\n",
            "However, based on the reasoning above, and looking at the relationship types in the given options:\n",
            "\n",
            "I choose \"per:friends\" to describe the relationship between Speaker 2 and Speaker 3, as well as the relationship between Speaker 3 and Speaker 4.\n",
            "\n",
            "VERDICT: per:friends\n",
            "\n",
            "###\n",
            "\n",
            "Based on the dialog, I can infer a close relationship between Speaker 2 and Speaker 3. Here's my reasoning:\n",
            "\n",
            "1. Speaker 2 interrupts the conversation between Speaker 1 and Speaker 2 to inform Speaker 3 about the proposal.\n",
            "2. Speaker 2 then asks Speaker 3 to \"handle this,\" implying that Speaker 3 has a certain level of authority or influence over Speaker 3.\n",
            "3. Speaker 3 responds by calling out to Phoebe, using a familiar and playful tone, indicating a close relationship.\n",
            "4. Later, when Speaker 2 introduces Speaker 3 to Phoebe, Speaker 3 calls Phoebe by her first name, which suggests a friendly and intimate relationship.\n",
            "\n",
            "Considering these points, I believe that Speaker 2 and Speaker 3 have a close family relationship. Given the context, I'm going to choose:\n",
            "\n",
            "**per:spouse**\n",
            "\n",
            "This choice seems most plausible, given that Speaker 2 introduces Speaker 3 as \"my husband\" and uses the phrase \"my husband just gave your boyfriend some very bad advice.\"\n",
            "\n",
            "VERDICT: \n",
            "**per:spouse**\n",
            "\n",
            "###\n",
            "\n",
            "Character relationships can be inferred by understanding the context, tone, and language used in the dialogue. In this case, the dialogue revolves around a proposal and the subsequent realization that Phoebe is already seeing someone named Mike. Here's my reasoning:\n",
            "\n",
            "* Speaker 2 (Monica) and Speaker 3 (not directly identified, but based on the context, should be Rachel) are friends of Phoebe's and David. When Speaker 2 says \"Monica, can I talk to you for a sec?\", it implies that they share a close, personal relationship, likely as friends.\n",
            "* Speaker 1 (David) proposes to Phoebe, which doesn't directly involve Monica or Rachel. However, when Rachel gets involved, it suggests that she's likely Phoebe's friend as well.\n",
            "* When Rachel (Speaker 3) gets involved, she's already on a first-name basis with Phoebe, which further supports the idea that they're friends.\n",
            "\n",
            "Considering the relationships that could exist between these characters, I rule out the following:\n",
            "\n",
            "* 'per:spouse' - None of the dialogue implies that Monica or Rachel are married to David or Mike.\n",
            "* 'per:children' - There's no mention of children.\n",
            "* 'per:boss' or 'per:subordinate' - The dialogue doesn't suggest a work relationship between these characters.\n",
            "* 'per:girl/boyfriend' - While Phoebe is in a relationship with someone, that's not between the main characters (Monica, Rachel, and David).\n",
            "\n",
            "After considering the context, tone, and familiar relationships between the characters, the most likely relationship between Speaker 2 (Monica) and Speaker 3 (Rachel) is:\n",
            "\n",
            "PER: FRIENDS\n",
            "\n",
            "Final Answer:\n",
            "VERDICT: 'per:friends'\n",
            "\n",
            "###\n",
            "\n",
            "After analyzing the dialog, I predict a relationship of 'per:friends' between Speaker 2 and Speaker 3. Here's my reasoning:\n",
            "\n",
            "* Speaker 2 and Speaker 3 engage in a conversation where they discuss Speaker 2's friend, David, proposing to Phoebe. This suggests that Speaker 2 and Speaker 3 are familiar with David and Phoebe, and are privy to their personal lives.\n",
            "* Speaker 2 shares the news with Speaker 3, and Speaker 3 takes an active role in \"handling\" the situation, which implies that they are close friends.\n",
            "* Throughout the conversation, Speaker 2 and Speaker 3 engage in banter and teasing, such as Speaker 2's sarcastic comment about Roseanne Rosannadanna. This lighthearted and playful tone is typical of close friendships.\n",
            "* There is no indication of a more intimate or familial relationship between Speaker 2 and Speaker 3, and no evidence of a professional relationship either.\n",
            "\n",
            "Based on these observations, I believe that Speaker 2 and Speaker 3 are friends.\n",
            "\n",
            "VERDICT: \n",
            "per:friends\n",
            "\n",
            "###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a self-consistency-based classifier."
      ],
      "metadata": {
        "id": "L6zkKAaUhnVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def most_frequent(List):\n",
        "    occurence_count = Counter(List)\n",
        "    return occurence_count.most_common(1)[0][0]\n",
        "\n",
        "class RelationClassifierSelfConsistency():\n",
        "    def __init__(self, client: OpenAI, model: str, n_trials: int = 5):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.n_trials = n_trials\n",
        "        self.raw_classes = [\"friends\", \"spouse\", \"children\", \"parents\",\n",
        "                            \"siblings\", \"girl/boyfriend\", \"boss\", \"subordinate\"]\n",
        "\n",
        "    def predict(self, dialog, character_x, character_y, verbose=False):\n",
        "        reasoning_completion = self.client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"You are an expert in Natural Nanguage Understanding.\n",
        "You are gived a dialog and two characters participating or mentioned in this dialog.\n",
        "You need to predict relationships between these characters choosing from the following list:\n",
        "- friends\n",
        "- spouse\n",
        "- children\n",
        "- parents\n",
        "- siblings\n",
        "- girl/boyfriend\n",
        "- boss\n",
        "- subordinate\n",
        "Provide a clear reasoning justifying your choice. Then write your final answer after #VERDICT:\n",
        "Now, take a deep breath and work out this problem step by step. If you do well, I'll tip you 200$.\n",
        "\n",
        "DIALOG: {dialog}\n",
        "\n",
        "FIRST CHARACTER: {character_x}\n",
        "\n",
        "SECOND CHARACTER: {character_y}\n",
        "\n",
        "REASONING:\"\"\"\n",
        "                }\n",
        "            ],\n",
        "            model=self.model,\n",
        "            n=n_trials # That's the main difference.\n",
        "            )\n",
        "\n",
        "        reasoning_completions = []\n",
        "        verdicts = []\n",
        "        for i in range(n_trials):\n",
        "            reasoning = reasoning_completion.choices[i].message.content\n",
        "            reasoning_completions.append(reasoning)\n",
        "\n",
        "            # Extract whatever is after #VERDICT:\n",
        "            re_match = re.search(r\"#VERDICT(.*)\", reasoning, re.DOTALL)\n",
        "            if re_match:\n",
        "                extracted_answer = re_match.group(1).strip()\n",
        "            else:\n",
        "                extracted_answer = \"Failed to parse\"\n",
        "\n",
        "            # Parse the answer\n",
        "            verdict = extracted_answer.lower().strip(\"'\\\".; \")\n",
        "            if verdict == \"boyfriend\" or verdict == \"girlfriend\":\n",
        "                verdict = \"girl/boyfriend\"\n",
        "            if verdict in self.raw_classes:\n",
        "                verdict = \"per:\" + verdict\n",
        "            else:\n",
        "                verdict = \"per:failed\"\n",
        "\n",
        "            verdicts.append(verdict)\n",
        "\n",
        "        final_verdict = most_frequent(verdicts)\n",
        "        if verbose:\n",
        "            return {\n",
        "                \"reasoning_completions\": reasoning_completions,\n",
        "                \"verdicts\": verdicts,\n",
        "                \"verdict\": final_verdict\n",
        "            }\n",
        "        else:\n",
        "            return final_verdict"
      ],
      "metadata": {
        "id": "X93jxHXWjY-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see if self-consistency is able to improve the results of **Llama-3.1-8B**\n",
        "\n",
        "**This may take time!**"
      ],
      "metadata": {
        "id": "v0GWg4NimrQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE THIS LATER\n",
        "\n",
        "classifier_sc = RelationClassifierSelfConsistency(\n",
        "    client=client, model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", n_trials=5\n",
        ")\n",
        "\n",
        "result = classifier_sc.predict(\n",
        "    dialog_data_short[5][0], dialog_data_short[5][1]['x'], dialog_data_short[5][1]['y'],\n",
        "    verbose=True)"
      ],
      "metadata": {
        "id": "x67SiSt6hnVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's classify all the statements and check the accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "-piSLTqbhnVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "current_configuration = \"Meta-Llama-3.1-8B-Instruct, self-consistency\"\n",
        "results = []\n",
        "# If you want, do it for dialog_data_short[-20:] to save time\n",
        "for dialog, relations in tqdm(dialog_data_short):\n",
        "    results.append(classifier_sc.predict(dialog, relations['x'], relations['y'], verbose=True))\n",
        "\n",
        "completions_log[current_configuration] = results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac067ad-571a-48b6-d54d-23d267a3b493",
        "id": "oc9thDfThnVO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [18:04<00:00, 21.69s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we check both the failed extraction rate and the classification accuracy."
      ],
      "metadata": {
        "id": "7XvAH1CZnKn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verdicts = [result[\"verdict\"] for result in results]\n",
        "print(sum([verdict == \"per:failed\" for verdict in verdicts]) / len(verdicts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f744e5d-f72f-4199-94eb-288f9a5e6acc",
        "id": "WWouSrHAhnVO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['per:friends', 'per:parents', 'per:parents', 'per:friends', 'per:girl/boyfriend', 'per:spouse', 'per:girl/boyfriend', 'per:boss', 'per:friends', 'per:friends', 'per:boss', 'per:friends', 'per:boss', 'per:spouse', 'per:girl/boyfriend', 'per:boss', 'per:friends', 'per:girl/boyfriend', 'per:spouse', 'per:friends', 'per:friends', 'per:girl/boyfriend', 'per:girl/boyfriend', 'per:friends', 'per:girl/boyfriend', 'per:siblings', 'per:boss', 'per:friends', 'per:girl/boyfriend', 'per:spouse', 'per:friends', 'per:friends', 'per:spouse', 'per:friends', 'per:siblings', 'per:girl/boyfriend', 'per:siblings', 'per:ex-spouse', 'per:parents', 'per:spouse', 'per:friends', 'per:girl/boyfriend', 'per:siblings', 'per:spouse', 'per:girl/boyfriend', 'per:parents', 'per:children', 'per:boss', 'per:boss', 'per:friends']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verdicts = verdicts_raw\n",
        "verdicts_log[current_configuration] = verdicts"
      ],
      "metadata": {
        "id": "_AM_qewFhnVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(verdicts_true[10:], verdicts[10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4175b7b0-c02b-4728-f0e6-54a23c34a04e",
        "id": "PrYxsF0-hnVO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.675"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's almost like we had with Llama-3.1-405b. Now, let's save our logs to avoid losing all the results:"
      ],
      "metadata": {
        "id": "jv7T6M9vskHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(completions_log, open(\"completions_log.pkl\", \"wb\"))\n",
        "pickle.dump(verdicts_log, open(\"verdicts_log.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "D6lnpXZDhnVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing the cost\n",
        "\n",
        "To wrap up the dialog relationship classifier task, let's calculate the LLM API cost for each of the scenarios using\n",
        "\n",
        "* Prices from the [Nebius AI Studio model reference](https://studio.nebius.ai/)\n",
        "* Token counts from the prompts and completions that we diligently logged."
      ],
      "metadata": {
        "id": "3K-l5JIxs_HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Models costs, per 1M tokens:\n",
        "costs = {\n",
        "    '405B': {\n",
        "        'input': 1,\n",
        "        'output': 3\n",
        "    },\n",
        "    '8B': {\n",
        "        'input': 0.02,\n",
        "        'output': 0.06\n",
        "    }\n",
        "}\n",
        "\n",
        "for key, value in completions_log.items():\n",
        "    print(f'=== With {key} ===')\n",
        "    total_input_tokens = 0\n",
        "    total_output_tokens = 0\n",
        "    for result in value:\n",
        "        for k, v in result.items():\n",
        "            if 'completion' in k:\n",
        "                if isinstance(v, list):\n",
        "                    for completion in v:\n",
        "                        total_input_tokens += completion.usage.prompt_tokens\n",
        "                        total_output_tokens += completion.usage.completion_tokens\n",
        "                else:\n",
        "                    total_input_tokens += v.usage.prompt_tokens\n",
        "                    total_output_tokens += v.usage.completion_tokens\n",
        "    if '405' in key:\n",
        "        model_size = '405B'\n",
        "    elif '8B' in key:\n",
        "        model_size = '8B'\n",
        "    else:\n",
        "        print('And what is that?..')\n",
        "    input_cost = total_input_tokens / 1000000 * costs[model_size]['input']\n",
        "    output_cost = total_output_tokens / 1000000 * costs[model_size]['output']\n",
        "    total_cost = input_cost + output_cost\n",
        "\n",
        "    print(f'''\n",
        "        Input cose: {input_cost}\n",
        "        Output cost: {output_cost}\n",
        "        Total cost: {total_cost}\n",
        "              ''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWYLX15Asp-I",
        "outputId": "82f19e70-cab0-4814-ce4d-6a872ac9f4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== With Meta-Llama-3.1-405B-Instruct, chain ===\n",
            "\n",
            "        Input cose: 0.046945\n",
            "        Output cost: 0.049715999999999996\n",
            "        Total cost: 0.096661\n",
            "              \n",
            "=== With Meta-Llama-3.1-8B-Instruct, chain ===\n",
            "\n",
            "        Input cose: 0.00084292\n",
            "        Output cost: 0.00088362\n",
            "        Total cost: 0.00172654\n",
            "              \n",
            "=== With Meta-Llama-3.1-8B-Instruct, few-shot ===\n",
            "\n",
            "        Input cose: 0.00229196\n",
            "        Output cost: 0.0006172199999999999\n",
            "        Total cost: 0.00290918\n",
            "              \n",
            "=== With Meta-Llama-3.1-8B-Instruct, self-consistency ===\n",
            "\n",
            "        Input cose: 0.0116306\n",
            "        Output cost: 0.00359088\n",
            "        Total cost: 0.015221479999999999\n",
            "              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, even self-consistency, Llama-3.1-8B is still way cheaper than Llama-3.1-405B. Moreover, we could greatly increase `n_trials` before we hit the price of the larger model.\n",
        "\n",
        "**Key takeaway**: always be aware of the larger model vs smarter strategy trade-off and take costs into account."
      ],
      "metadata": {
        "id": "i_O6BFRzwIod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice, part 2. Your turn now!\n",
        "\n",
        "Now it's your time to put `MMLUEvaluator` we've played with in the previous notebook to good use! Choose one of the math-related fields (you can check the choice in [the paper](https://arxiv.org/pdf/2009.03300)) and select first 50 examples.\n",
        "\n",
        "**Your task.** Compare accuracy on this small dataset when using:\n",
        "\n",
        "- **Llama-3.1-70B** with CoT suppression,\n",
        "- **Llama-3.1-8B** with CoT suppression,\n",
        "- **Llama-3.1-70B** with basic CoT,\n",
        "- **Llama-3.1-8B** with basic CoT,\n",
        "- **Llama-3.1-8B** with self-consistency.\n",
        "\n",
        "Also, compare the cost of processing 50 examples with:\n",
        "- **Llama-3.1-70B** without any additional tricks,\n",
        "- **Llama-3.1-8B** with all additional tricks you can use.\n",
        "Can you reach **Llama-3.1-70B**'s quality with **Llama-3.1-8B** while staying cheaper?"
      ],
      "metadata": {
        "id": "3x2RRNcdmSd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Your experiments here>"
      ],
      "metadata": {
        "id": "WjmS7NP3oIi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice, part 3. PRMs and Beam Search"
      ],
      "metadata": {
        "id": "Uu4vQuNvobkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a PRM\n",
        "\n",
        "In this section, you'll play with a **PRM** (**Process Reward Model**).\n",
        "\n",
        "At the moment, we're not aware of any good PRM API (if you know any, please share with us!), so we'll have to use an open source model. Namely, we'll use this one: [RLHFlow/Llama3.1-8B-PRM-Deepseek-Data](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data), which is a fine tune of Llama-3.1-8B. We haven't yet discussed using open-source models, but you'll have all the code, so we hope you won't have problems with it.\n",
        "\n",
        "**To run this model, you'll need a GPU**. The model itself will take around 16Gb, and some more GPU memory will be used for inference. Either L40s in Nebius cloud or L4 in Colab should be enough for the task. Just don't forget to switch off (and better to delete) the virtual machine after you finish; otherwise, you'll be charged for the time it stays idle."
      ],
      "metadata": {
        "id": "vVxkUv4_svUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've created a wrapper class `ProcessRewardModel`, which loads the model for you and also offers an `evaluate_partial_solution(prompt, partial solution)` method which incapsulates all the details of calling the model allowing you not to think about how it's done under the hood.\n",
        "\n",
        "However, if you're curious, we'll share a little bit about how this model works. It is a chat model, and to each user's message it's trained to answer with a `\"+\"` or a `\"-\"`. The probability of predicting `\"+\"` is exactly the score of the partial solution (\"how likely it is for it to give a correct solution, if continued\").\n",
        "\n",
        "A multi-step solution, when scored by this PRM, is transformed into a dialog like this:\n",
        "\n",
        "```\n",
        "[\n",
        "      {\"role\": \"user\", \"content\": \"Convert the point $(0,3)$ in rectangular coordinates to polar coordinates. To convert from rectangular coordinates $(x, y)$ to polar coordinates $(r, \\\\theta)$, we can use the formulas\\n\\\\[r = \\\\sqrt{x^2 + y^2}\\\\]\\n\\\\[\\\\theta = \\\\arctan \\\\frac{y}{x}\\\\]\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "      {\"role\": \"user\", \"content\": \"In this case, the rectangular coordinates are $(0,3)$, so $x = 0$ and $y = 3$.\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "      {\"role\": \"user\", \"content\": \"First, we calculate $r$:\\n\\\\[r = \\\\sqrt{0^2 + 3^2} = \\\\sqrt{9} = 3\\\\]\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "      {\"role\": \"user\", \"content\": \"Next, we calculate $\\\\theta$:\\n\\\\[\\\\theta = \\\\arctan \\\\frac{3}{0}\\\\]\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "      {\"role\": \"user\", \"content\": \"Since the tangent function is not defined for $x = 0$, we need to use a special case. When $x = 0$, $\\\\theta = \\\\frac{\\\\pi}{2}$ if $y > 0$, and $\\\\theta = \\\\frac{3\\\\pi}{2}$ if $y < 0$.\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "      {\"role\": \"user\", \"content\": \"In this case, $y = 3 > 0$, so $\\\\theta = \\\\frac{\\\\pi}{2}$.\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "      {\"role\": \"user\", \"content\": \"So, the polar coordinates equivalent to $(0,3)$ are $\\\\boxed{(3,\\\\frac{\\\\pi}{2})}$.\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"+\"},\n",
        "]\n",
        "```\n",
        "\n",
        "Source: [model's github](https://github.com/RLHFlow/RLHF-Reward-Modeling/tree/main/math-rm)\n",
        "\n",
        "Basically, `evaluate_partial_solution` does the follows:\n",
        "\n",
        "* Splits the solution by `\"\\n\\n\"` (paragraph end) which seems to be a proxy for a change of \"thoughts\" in the PRM's training,\n",
        "* Turns the solutions steps into a dialog.\n",
        "* Returns an estimate of the probability of generating a `\"+\"`.\n",
        "\n",
        "The code below is mostly an adaptation of [this evaluation script](https://github.com/RLHFlow/RLHF-Reward-Modeling/blob/main/math-rm/prm_evaluate.py).\n"
      ],
      "metadata": {
        "id": "L_CRBk911Joo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "class ProcessRewardModel:\n",
        "    def __init__(self, model: str = \"RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\"):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model,\n",
        "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        # Set up tokenizer settings\n",
        "        self.tokenizer.padding_side = \"right\"\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        self.model.config.pad_token_id = self.model.config.eos_token_id\n",
        "\n",
        "        # Get token IDs for + and -\n",
        "        self.plus_token_id = self.tokenizer.encode(\"+\")[-1]\n",
        "        self.minus_token_id = self.tokenizer.encode(\"-\")[-1]\n",
        "        self.candidate_tokens = [self.plus_token_id, self.minus_token_id]\n",
        "\n",
        "    def evaluate_partial_solution(self, prompt: str, partial_solution: str) -> float:\n",
        "        \"\"\"Evaluate a partial solution using PRM.\"\"\"\n",
        "        # Split solution into steps\n",
        "        steps = [step.strip() for step in partial_solution.split(\"\\n\\n\") if step.strip()]\n",
        "\n",
        "        # Convert to chat format starting with prompt\n",
        "        conversation = []\n",
        "        first_text = prompt + \" \" + steps[0]\n",
        "        conversation.append({\"role\": \"user\", \"content\": first_text})\n",
        "        conversation.append({\"role\": \"assistant\", \"content\": \"+\"})\n",
        "\n",
        "        for step in steps[1:]:\n",
        "            conversation.append({\"role\": \"user\", \"content\": step})\n",
        "            conversation.append({\"role\": \"assistant\", \"content\": \"+\"})\n",
        "\n",
        "        # Remove last assistant message for scoring\n",
        "        conversation = conversation[:-1]\n",
        "\n",
        "        # Get model prediction\n",
        "        input_ids = self.tokenizer.apply_chat_template(\n",
        "            conversation,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_ids)\n",
        "            logits = outputs.logits[:, -3, self.candidate_tokens]\n",
        "            scores = logits.softmax(dim=-1)\n",
        "            plus_prob = scores[:, 0].item()  # Probability of + token\n",
        "\n",
        "        return plus_prob"
      ],
      "metadata": {
        "id": "u0LHXcqtzGmp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the PRM and score with it one correct solution and one incorrect solution of the equation $x^2 - x - 2 = 0$."
      ],
      "metadata": {
        "id": "NVNApxSN5B1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize PRM once\n",
        "prm = ProcessRewardModel(model=\"RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "d9541f68623f47a3b63688031800c044",
            "45fd267b9e2b470c872576b29c4c0f03",
            "a22196074f444ce8a1041d4f1de957ee",
            "174f78be17f9468bb475f8c4879acc4e",
            "a8eb3c67e05942aaac802cf14ac26902",
            "24e9378e24944bfaa97af667dccfd3a6",
            "bf081bba15fe4a0ea7c91c93b35a4975",
            "a6be8d373e03481391ff309f07e1bb16",
            "255dc4b271b440fcb7505352de6d4844",
            "80725acd6d854d3aba38337bb50ca7b3",
            "5209cec6e5d149798ca4ff4f4a6a9f92",
            "a7e5b20b2a51432da46ddf987b65a816",
            "326ea9fbff1246e19ff13665bec35ed9",
            "ee5447b9e099406dbfbcab8a46df57dd",
            "f73b2965b7f14ec183369462187953b1",
            "b7ad40360c2f4c78ab2a8e449b5e587f",
            "1478f905f7e140a1b2df33651c06f437",
            "c46f93a1e5e64d258e1389355025820a",
            "5ba98f01b7e04eacbc040705365db9ae",
            "b2434c25cb834d65b970d5f504a2be8f",
            "de1c295a391e4b05a8a9e2df444510df",
            "0eea8feb343a4e09b6950b9df302d5b0",
            "b87f777769bd46aaba333ca7ca398978",
            "a0c5099a529d4320995a869680df9b54",
            "d7d1fbd01e5647b1b68a9b29543b8c3d",
            "5c223e07622647d8867ee39afd25b520",
            "9273a9d1f5314616a4124bb9cafd5f5e",
            "dc85bffa329d410a9875dd7de6e1a1f7",
            "4c4a5dc2ae7143d79daadd596e720a7d",
            "d3e4721be33843738ce2df03f7636f9b",
            "5841cb63c31d45b18e598cf4bc281c3d",
            "563624004d6146d3bc5874d23151af29",
            "cde388ca649e452db931d3bd1680f622",
            "2e8c74eb829c41d9babe09edf33a9e7d",
            "f330cdea43734efba39bb3d916a20c2b",
            "dcd1aec5f0894ee98bd1886097d1910d",
            "86cbe47e65a145469e9e4007b1ed1883",
            "763416e26fd645c596885122fa3e429d",
            "992e20773834477ea12b600c9e579e74",
            "c98ebf1681334d79bd4f60d34c7568d2",
            "4f01a1fb6960472dba368e1a1998bb12",
            "f2601c82f73b407987099153293b0fea",
            "90f106acc637409989d5d6076aa4dba9",
            "37db92fc0b4143ed930768bb267a5dc2",
            "906e6e767e864ff68dc25352b128cad8",
            "5fc853dc50ab48f3aacab4100df0be04",
            "431e685485204f72bd7ba945ac46d2bb",
            "d468face879b48d192c995198ac84622",
            "03efa0106bfa4b96a2926e045d32c7b1",
            "42fa8aeeca304f428ad08ea7be40f6a9",
            "32fc206b49f9431b821de4a3b4a5cfaf",
            "b100d7481feb4911b23b54551bbea9be",
            "c00f4dfcce3042c89798d34a439cb35d",
            "9a630d67676b4428ba853a9bb4c15d08",
            "8fe821830bd04db990d388bab8d30adc",
            "e63f4317a08f4ec9bba057f83296a80a",
            "0b6af995e925452a9a03c7c7c7d9039a",
            "fcfa370177214516a5e8c879d245b618",
            "5ae242d90926410da3ee80a215362b71",
            "70cb6b932b484aa39a237107b3603ed2",
            "f18e6fb6381a4c7db56d632b5af768e2",
            "578ac9ef20f7414093a619c0a3588fed",
            "1ade592d07a147a29d2731e97cd986b6",
            "e6c629bbbe6d48b093a9beb8fd37fdde",
            "7a3c0ce63cb049668853cbf7b493e167",
            "acd3d02e6f0b4cb390b51cd21e0aefe9",
            "dadcb13380bc4f0e94047d75281d729a",
            "fe517ba9e1474ffb8f35f650e5636573",
            "999b53ba688b40b987ef02d628d74c24",
            "105bad09865c435ab3b8bb59373f69d7",
            "60826be82d48415db7dfb3026660df79",
            "3e6dd74328374e15b70d9d9cff22b049",
            "0a49be973cc24c48ab25684ede17c6a6",
            "ba9747d7ea98452f9e3692159ffa6589",
            "5a498dedde9b4e3a9fb40f7277948b87",
            "0eb24284136545fc95e06ef5a8c8bd11",
            "bf7003b8ca1b4ec486241273bf7149e7",
            "21604b40da484f7f81eddf008154e836",
            "dfcaf553b8f844a89035716c60d9f4a4",
            "6c77d35de2484bb4aa2d015f51920e57",
            "e51f753ab1df4a47b1b610f1d067015a",
            "38098cea0ae54abeb4760979bd1538ce",
            "4cd6901da37d40fd9f6ea27dbb6ed3bb",
            "b6e5edcc401548e1bdaa29ce57d0649b",
            "53f3155fe295422897b49ca0434b7fa2",
            "fb250ceed5154caa87e073a7b39d7ec2",
            "f1688f9957ab40bd8ba2f05378b6608c",
            "94de96b1e672406484f919551d9c88b1",
            "626e5c1fa8ef4fc3ba3155493ccddc53",
            "018a1ad4db014aeea338e76b5df1f1e4",
            "b0c9f1f4be884085858be44f0a0b2567",
            "52a4d1a3c8174d52902a846f0f27fb3c",
            "9aa14ef1f8004f958802aab8fc12289b",
            "e83ab72de3ef4636afa0008ef6fdc383",
            "747f96dbbf4240d9b776e6d8337d1276",
            "38f0a18a69274f41be50108c8fa9aab0",
            "dac398e0d6c0412da8b8ab293c0e597f",
            "b8e7c421224b4c06968f35dbec8b3288",
            "e153c87702ca4865a4589f3ddba1233b",
            "f8894b85fd6a4e6db5082142b19c35b5",
            "1ead4b423f13471b83952d2fd9ee7c35",
            "bead09bdb4504e9bb2780ceebf8be9d4",
            "c663126fb549412a9520d26446f0e092",
            "eca35a88341048e4a752c01234882d1b",
            "99e30fc16f674874a6d7b0be2088f213",
            "5c6f128206b74e39940da05405810100",
            "5c9c91244b114c83be987e2f36f24c60",
            "ef03031acab545968e3a718ed79749ee",
            "4a04a051851748468d12a6d7944752ff",
            "142ba229d9734f918c1415bc34d6ab0d",
            "77f3b352b2144bc7a8e33ef3e4047571",
            "100fd4c5a3264311a215d5a2d79fd137",
            "3d07db1bf08341a3a11d2a46697a2713",
            "eaf4919df6c3455a80622a592ff8c6ca",
            "c610bdcb4ead4dd984c561fcb941de53",
            "c5f6795dba3d4d538ae370123d1d8fff",
            "b7549d348f5648a1af548f2d2f4551af",
            "0ffaaa047d584a94903c9223ebfb3de4",
            "4dfb596ed4bd449a80aecee3d5248d71",
            "54d1a818ada44b3bb2d36355a4f42c7f",
            "bd20878caacf4ac78a4433506e68c34e",
            "30ec7745648348cea3e5f797434347c0",
            "530384b312674eac9b32780c10d977e4",
            "dfbb8e90d45f43b7860818b5b823de88",
            "679ed51171984388870b6a90986188ae",
            "fdecad77bdf745e69acf5117b8159ca0",
            "b602f5e2096044e9aeac6bc170393de7",
            "1f8d52bce37649dbbb838465110e8748",
            "ab118ab763bd4823bb8f460b1a4f5469",
            "8c0f859e896c4a31a2ce6589e13fb2d3",
            "4bd19d24c2f44a03afacd7b9e7dd3650",
            "89b69c60c8d24e11b9e71a877f00b820"
          ]
        },
        "id": "LTH6ZP8173Dh",
        "outputId": "fa78c4c7-afdd-470b-f270-69340a8a6c22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9541f68623f47a3b63688031800c044"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7e5b20b2a51432da46ddf987b65a816"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b87f777769bd46aaba333ca7ca398978"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/896 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e8c74eb829c41d9babe09edf33a9e7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "906e6e767e864ff68dc25352b128cad8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e63f4317a08f4ec9bba057f83296a80a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dadcb13380bc4f0e94047d75281d729a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21604b40da484f7f81eddf008154e836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "626e5c1fa8ef4fc3ba3155493ccddc53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8894b85fd6a4e6db5082142b19c35b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77f3b352b2144bc7a8e33ef3e4047571"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30ec7745648348cea3e5f797434347c0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Solve the equation $x^2 - x - 2 = 0$.\"\n",
        "\n",
        "# A correct solution\n",
        "solution = \"\"\"Factor the left part as $(x + 1)(x - 2)$.\n",
        "\n",
        "Now, let's rewrite the initial equation $x^2 - x - 2 = 0$ as $(x + 1)(x - 2) = 0$.\n",
        "\n",
        "Thus, either $x + 1 = 0$ or $x - 2 = 0$.\n",
        "\n",
        "Thus, the roots are -1 and 2\"\"\"\n",
        "\n",
        "# Get step-score pairs\n",
        "steps = solution.split(\"\\n\\n\")\n",
        "for i in range(len(steps)):\n",
        "    partial_solution = \"\\n\\n\".join(steps[:i+1])\n",
        "    step_score = prm.evaluate_partial_solution(prompt, partial_solution)\n",
        "    print(f\"\\n#PARTIAL SOLUTION:\\n {partial_solution}\")\n",
        "    print(f\"#SCORE: {step_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62G1-P8LRq5k",
        "outputId": "d0de3f81-21fb-445e-deb2-500cf3b0f469"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Factor the left part as $(x + 1)(x - 2)$.\n",
            "#SCORE: 0.9995\n",
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Factor the left part as $(x + 1)(x - 2)$.\n",
            "\n",
            "Now, let's rewrite the initial equation $x^2 - x - 2 = 0$ as $(x + 1)(x - 2) = 0$.\n",
            "#SCORE: 0.9478\n",
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Factor the left part as $(x + 1)(x - 2)$.\n",
            "\n",
            "Now, let's rewrite the initial equation $x^2 - x - 2 = 0$ as $(x + 1)(x - 2) = 0$.\n",
            "\n",
            "Thus, either $x + 1 = 0$ or $x - 2 = 0$.\n",
            "#SCORE: 0.9209\n",
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Factor the left part as $(x + 1)(x - 2)$.\n",
            "\n",
            "Now, let's rewrite the initial equation $x^2 - x - 2 = 0$ as $(x + 1)(x - 2) = 0$.\n",
            "\n",
            "Thus, either $x + 1 = 0$ or $x - 2 = 0$.\n",
            "\n",
            "Thus, the roots are -1 and 2\n",
            "#SCORE: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll comment briefly on the output above. The solution consists of 4 paragraphs and is thus split into 4 individual \"thoughts\" (solution steps). In the cycle, we evaluate:\n",
        "\n",
        "* Step 1\n",
        "* Steps 1+2\n",
        "* Steps 1+2+3\n",
        "* Steps 1+2+3+4 (the full solution)\n",
        "\n",
        "As you see, all the scores are quite high, and the full solution gets max grade (and it's correct indeed)."
      ],
      "metadata": {
        "id": "1rWdPZ2f5c0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Solve the equation $x^2 - x - 2 = 0$.\"\n",
        "\n",
        "# An incorrect solution\n",
        "solution = \"\"\"Rewrite the equation as $x^2 = x + 2$.\n",
        "\n",
        "Divide both parts by x: $x = 1 + 2x$.\n",
        "\n",
        "Rewrite it as $x = 1$. Thus, x = 1.\"\"\"\n",
        "\n",
        "# Get step-score pairs\n",
        "steps = solution.split(\"\\n\\n\")\n",
        "for i in range(len(steps)):\n",
        "    partial_solution = \"\\n\\n\".join(steps[:i+1])\n",
        "    step_score = prm.evaluate_partial_solution(prompt, partial_solution)\n",
        "    print(f\"\\n#PARTIAL SOLUTION:\\n {partial_solution}\")\n",
        "    print(f\"#SCORE: {step_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tptw3SWWRuQZ",
        "outputId": "3edcbcde-d306-44dd-cd55-9af4b19f9891"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Rewrite the equation as $x^2 = x + 2$.\n",
            "#SCORE: 0.5889\n",
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Rewrite the equation as $x^2 = x + 2$.\n",
            "\n",
            "Divide both parts by x: $x = 1 + 2x$.\n",
            "#SCORE: 0.1550\n",
            "\n",
            "#PARTIAL SOLUTION:\n",
            " Rewrite the equation as $x^2 = x + 2$.\n",
            "\n",
            "Divide both parts by x: $x = 1 + 2x$.\n",
            "\n",
            "Rewrite it as $x = 1$. Thus, x = 1.\n",
            "#SCORE: 0.3999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For an incorrect solution, the scores are much lower. Moreover:\n",
        "\n",
        "* The first step, which is somewhat strange in solving a simple quadratic equation, is scored as dubious.\n",
        "* The next step, which intoduces a serious mistake, gets a very low grade.\n",
        "\n",
        "So, the PRM seems to be somewhat aligned with our math intuition."
      ],
      "metadata": {
        "id": "Ohq8CNw06Z-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam Search\n",
        "\n",
        "In this part, we'll share our implementation of **Beam Search** - the class `MathBeamSearch`. It's quite big, so we'll comment on several important things about it:\n",
        "\n",
        "* It uses a [min heap](https://en.wikipedia.org/wiki/Heap_(data_structure)) to store the newly generated completions and their scores, because this data structure allows for fast addition and for fast deletion of minimal elements.\n",
        "\n",
        "  We chose the `heapq` implementation; because `heapq` a max heap, we actually store pairs `(-score, partial_solution)` to make a min heap out of it.\n",
        "\n",
        "* Each time, the LLM is prompted to generate a next logical step of the solution and to keep it on one line. This (in most cases) allows to establish `\"\\n\\n\"` as separators between individual \"thoughts\", as expected by the PRM.\n",
        "\n",
        "* We prompt the LLM to output `#ANSWER: <answer>` when it obtains the final answer. This allows to finalize successful solutions without continuing them aimlessly intil they hit `max_steps` \"thoughts\"."
      ],
      "metadata": {
        "id": "6CK4W1bz7o2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from openai import OpenAI\n",
        "\n",
        "class LLMClient:\n",
        "    \"\"\"Wrapper for OpenAI-compatible API clients with consistent interface.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        client: OpenAI,\n",
        "        model: str,\n",
        "        default_temperature: float = 0.0,\n",
        "        default_max_tokens: int = 1024,\n",
        "        system_prompt: Optional[str] = None\n",
        "    ):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.default_temperature = default_temperature\n",
        "        self.default_max_tokens = default_max_tokens\n",
        "        self.system_prompt = system_prompt\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        temperature: Optional[float] = None,\n",
        "        max_tokens: Optional[int] = None,\n",
        "        system_prompt: Optional[str] = None\n",
        "    ) -> str:\n",
        "        \"\"\"Generate completion with consistent interface across different LLM providers.\"\"\"\n",
        "        messages = []\n",
        "\n",
        "        # Use provided system prompt or fall back to default\n",
        "        current_system_prompt = system_prompt or self.system_prompt\n",
        "        if current_system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": current_system_prompt})\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            temperature=temperature if temperature is not None else self.default_temperature,\n",
        "            max_tokens=max_tokens if max_tokens is not None else self.default_max_tokens\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "class MathBeamSearch:\n",
        "    \"\"\"Beam search implementation for math problem solving.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        prm: ProcessRewardModel,\n",
        "        llm_client: LLMClient,\n",
        "        beam_width: int = 2,\n",
        "        max_steps: int = 10\n",
        "    ):\n",
        "        self.prm = prm\n",
        "        self.llm_client = llm_client\n",
        "        self.beam_width = beam_width\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "    def generate_next_steps(self, prompt: str, partial_solution: str, num_continuations: int) -> List[str]:\n",
        "        \"\"\"Generate next possible steps using LLM.\"\"\"\n",
        "        if partial_solution:\n",
        "            message = f\"\"\"You are an expert math problem solver. Given a math problem and a partial solution, generate the next logical step.\n",
        "Keep the step concise and focused on one specific calculation or logical deduction.\n",
        "\n",
        "Problem:\n",
        "{prompt}\n",
        "\n",
        "Current partial solution:\n",
        "{partial_solution}\n",
        "\n",
        "Generate the next step in the solution. Only output:\n",
        "- the next step\n",
        "- #ANSWER: followed by your answer, if you can determine the final answer. If you output #ANSWER:, you need to output the actual answer after it.\n",
        "Don't output anything else!\n",
        "Keep the whole new step of the single line.\n",
        "If you need to write formulas, use latex $ markup to format them.\"\"\"\n",
        "        else:\n",
        "            message = f\"\"\"You are an expert math problem solver. Given a math problem, generate the first step of the solution.\n",
        "Keep the step concise and focused on one specific calculation or logical deduction.\n",
        "\n",
        "Problem:\n",
        "{prompt}\n",
        "\n",
        "Generate the first step in the solution. Only output:\n",
        "- the first step,\n",
        "- #ANSWER: followed by your answer, if you can determine the final answer. If you output #ANSWER:, you need to output the actual answer after it.\n",
        "Don't output anything else!\n",
        "Keep the whole first step of the single line.\n",
        "If you need to write formulas, use latex $ markup to format them.\"\"\"\n",
        "\n",
        "        responses = []\n",
        "        for _ in range(num_continuations):\n",
        "            response = self.llm_client.generate(\n",
        "                message\n",
        "            )\n",
        "            responses.append(response.strip())\n",
        "        return responses\n",
        "\n",
        "    def beam_search(self, prompt: str,\n",
        "            verbose: bool = False) -> List[Tuple[float, str]]:\n",
        "        \"\"\"Perform beam search to find the best solution.\"\"\"\n",
        "        # Initialize beam with empty solutions\n",
        "        current_beam = [(0.0, \"\", False)]  # (score, solution, is_finalized)\n",
        "\n",
        "        # Get initial steps\n",
        "        initial_continuations = self.generate_next_steps(prompt, None, self.beam_width)\n",
        "\n",
        "        # Initialize beam with scored initial steps\n",
        "        candidates = []\n",
        "        for continuation in initial_continuations:\n",
        "            score = self.prm.evaluate_partial_solution(prompt, continuation)\n",
        "            is_finalized = \"#ANSWER:\" in continuation\n",
        "            candidates.append((-score, continuation, is_finalized))  # Negative for max-heap\n",
        "            if verbose:\n",
        "                print(f\"\\nInitial step (score {score:.4f}):\")\n",
        "                print(f\"{continuation}\\n\")\n",
        "\n",
        "        # Select top-k candidates for initial beam\n",
        "        heapq.heapify(candidates)\n",
        "        current_beam = [(-score, solution, is_finalized)\n",
        "                       for score, solution, is_finalized in heapq.nsmallest(self.beam_width, candidates)]\n",
        "\n",
        "        # Beam search iterations\n",
        "        step = 0\n",
        "        while step < self.max_steps:\n",
        "            # Check if all solutions are finalized\n",
        "            if all(is_finalized for _, _, is_finalized in current_beam):\n",
        "                break\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\n=== Step {step + 1} ===\")\n",
        "            candidates = []\n",
        "\n",
        "            # Keep finalized solutions and generate continuations for unfinished ones\n",
        "            for score, partial_solution, is_finalized in current_beam:\n",
        "                if is_finalized:\n",
        "                    # Keep finalized solutions in candidates without modification\n",
        "                    candidates.append((-score, partial_solution, True))\n",
        "                else:\n",
        "                    # Generate continuations only for unfinished solutions\n",
        "                    continuations = self.generate_next_steps(\n",
        "                        prompt,\n",
        "                        partial_solution,\n",
        "                        self.beam_width\n",
        "                    )\n",
        "\n",
        "                    # Evaluate each continuation\n",
        "                    for continuation in continuations:\n",
        "                        new_solution = partial_solution + \"\\n\\n\" + continuation if partial_solution else continuation\n",
        "                        new_score = self.prm.evaluate_partial_solution(prompt, new_solution)\n",
        "                        is_finished = \"#ANSWER:\" in continuation\n",
        "                        candidates.append((-new_score, new_solution, is_finished))\n",
        "                        if verbose:\n",
        "                            print(f\"\\nCandidate (score {new_score:.4f}):\")\n",
        "                            print(f\"{continuation}\\n\")\n",
        "\n",
        "            # Select top-k candidates for next beam\n",
        "            heapq.heapify(candidates)\n",
        "            current_beam = [(-score, solution, is_finalized)\n",
        "                          for score, solution, is_finalized in heapq.nsmallest(self.beam_width, candidates)]\n",
        "\n",
        "            if verbose:\n",
        "                print(\"\\nSelected for next beam:\")\n",
        "                for score, solution, is_finalized in current_beam:\n",
        "                    status = \"FINALIZED\" if is_finalized else \"IN PROGRESS\"\n",
        "                    print(f\"\\nScore: {score:.4f} [{status}]\")\n",
        "                    print(f\"{solution}\\n\")\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        # Return all solutions (now guaranteed to include any finalized ones)\n",
        "        return [(score, solution) for score, solution, _ in current_beam]"
      ],
      "metadata": {
        "id": "na6WnFdI7vld"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it!"
      ],
      "metadata": {
        "id": "8p9D1d-pAG3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "# Create beam search instance\n",
        "beam_search = MathBeamSearch(\n",
        "    prm=prm,\n",
        "    llm_client=LLMClient(\n",
        "        client=client,\n",
        "        model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "        default_temperature=1,\n",
        "        default_max_tokens=8192\n",
        "    ),\n",
        "    beam_width=2,\n",
        "    max_steps=20\n",
        ")"
      ],
      "metadata": {
        "id": "IwwnCxO0AFti"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll turn on the `verbose` parameter to see all the intermediate results. (It's `False` by default.)"
      ],
      "metadata": {
        "id": "64HLqktJAt3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Inside a circle, two parallel chords are 6 units apart. One chord has length 14 and the other has length 10. Find the radius of the circle.\"\n",
        "\n",
        "# Run beam search\n",
        "results = beam_search.beam_search(prompt, verbose=True)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\n=== Final Results ===\")\n",
        "for score, solution in results:\n",
        "    print(f\"\\nScore: {score:.4f}\")\n",
        "    print(f\"{solution}\\n\")"
      ],
      "metadata": {
        "id": "wqivHBL2As3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "569c2100-1dfd-45e7-beeb-1821cf0ad607"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial step (score 0.2830):\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "\n",
            "Initial step (score 0.6875):\n",
            "Draw a perpendicular line from the center of the circle to each chord, and denote the radius of the circle as $r$. Let $d$ be the distance from the center of the circle to the chord with length 10, so the distance from the center of the circle to the chord with length 14 is $d+6$.\n",
            "\n",
            "\n",
            "=== Step 1 ===\n",
            "\n",
            "Candidate (score 0.4688):\n",
            "Using the Pythagorean theorem, we can set up two equations: $r^2 = d^2 + 5^2$ and $r^2 = (d+6)^2 + 7^2$.\n",
            "\n",
            "\n",
            "Candidate (score 0.5796):\n",
            "Apply the Pythagorean theorem to the two right triangles formed by the radii and the chords, resulting in the equations: $r^2 = d^2 + 5^2$ and $r^2 = (d+6)^2 + 7^2$.\n",
            "\n",
            "\n",
            "Candidate (score 0.8408):\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "\n",
            "Candidate (score 0.6670):\n",
            "Using the Pythagorean Theorem on the right triangle formed by the radius, the distance between the chords, and the half-length of the longer chord, we have: $r^2 = 6^2 + 7^2$\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 0.8408 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "\n",
            "Score: 0.6670 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "Using the Pythagorean Theorem on the right triangle formed by the radius, the distance between the chords, and the half-length of the longer chord, we have: $r^2 = 6^2 + 7^2$\n",
            "\n",
            "\n",
            "=== Step 2 ===\n",
            "\n",
            "Candidate (score 0.9951):\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "\n",
            "Candidate (score 0.9966):\n",
            "Equate the two expressions of $r^2$ obtained from the Pythagorean equations: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "\n",
            "Candidate (score 0.8706):\n",
            "$r^2 = 36 + 49$\n",
            "\n",
            "\n",
            "Candidate (score 0.7930):\n",
            "Substitute the value of $r^2$ from the equation above into a new Pythagorean equation for the radius, the distance between the chords, and the half-length of the shorter chord: $r^2 = 6^2 + 5^2$.\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 0.9966 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Equate the two expressions of $r^2$ obtained from the Pythagorean equations: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "\n",
            "Score: 0.9951 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "\n",
            "=== Step 3 ===\n",
            "\n",
            "Candidate (score 0.3398):\n",
            "Expand and simplify the equation: $49 + h^2 = 25 + (h^2 - 12h + 36)$\n",
            "\n",
            "\n",
            "Candidate (score 0.7251):\n",
            "Expand $(h-6)^2$ in the equation $7^2 + h^2 = 5^2 + (h-6)^2$ to obtain $49 + h^2 = 25 + h^2 - 12h + 36$.\n",
            "\n",
            "\n",
            "Candidate (score 1.0000):\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "\n",
            "Candidate (score 0.7266):\n",
            "Expand $(h-6)^2$ in the equation: $7^2 + h^2 = 5^2 + h^2 - 12h + 36$.\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 1.0000 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "\n",
            "Score: 0.7266 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand $(h-6)^2$ in the equation: $7^2 + h^2 = 5^2 + h^2 - 12h + 36$.\n",
            "\n",
            "\n",
            "=== Step 4 ===\n",
            "\n",
            "Candidate (score 0.6943):\n",
            "$49 + h^2 = 25 + h^2 - 12h + 36$, cancel out the $h^2$ terms: $49 = 25 - 12h + 36$.\n",
            "\n",
            "\n",
            "Candidate (score 0.9658):\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "\n",
            "Candidate (score 0.9985):\n",
            "Subtract $h^2$ from both sides of the equation: $7^2 = 5^2 - 12h + 36$.\n",
            "\n",
            "\n",
            "Candidate (score 0.8408):\n",
            "$7^2 + h^2 = 5^2 + h^2 - 12h + 36 \\Rightarrow 49 = 25 - 12h + 36$\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 0.9985 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand $(h-6)^2$ in the equation: $7^2 + h^2 = 5^2 + h^2 - 12h + 36$.\n",
            "\n",
            "Subtract $h^2$ from both sides of the equation: $7^2 = 5^2 - 12h + 36$.\n",
            "\n",
            "\n",
            "Score: 0.9658 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "\n",
            "=== Step 5 ===\n",
            "\n",
            "Candidate (score 0.9194):\n",
            "Subtract $5^2$ and $36$ from both sides of the equation: $49 - 25 - 36 = -12h$\n",
            "\n",
            "\n",
            "Candidate (score 0.7026):\n",
            "Subtract $5^2$ from both sides of the equation and add $12h$ to both sides: $7^2 - 5^2 = 36 - 12h$.\n",
            "\n",
            "\n",
            "Candidate (score 0.7280):\n",
            "Solve for $h$: $12h = 61 - 49 \\Rightarrow h = \\frac{12}{12}$\n",
            "\n",
            "\n",
            "Candidate (score 0.9204):\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 0.9204 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "\n",
            "Score: 0.9194 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand $(h-6)^2$ in the equation: $7^2 + h^2 = 5^2 + h^2 - 12h + 36$.\n",
            "\n",
            "Subtract $h^2$ from both sides of the equation: $7^2 = 5^2 - 12h + 36$.\n",
            "\n",
            "Subtract $5^2$ and $36$ from both sides of the equation: $49 - 25 - 36 = -12h$\n",
            "\n",
            "\n",
            "=== Step 6 ===\n",
            "\n",
            "Candidate (score 0.7007):\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "\n",
            "Candidate (score 0.7881):\n",
            "Divide both sides of the equation $12h = 12$ by 12 to find the value of $h$: $h = \\frac{12}{12} = 1$.\n",
            "\n",
            "\n",
            "Candidate (score 0.5679):\n",
            "Simplify the left-hand side of the equation: $-12 = -12h$.\n",
            "\n",
            "#ANSWER:\n",
            "\n",
            "\n",
            "Candidate (score 0.6226):\n",
            "Simplify the left-hand side of the equation: $-12 = -12h$\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 0.7881 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "Divide both sides of the equation $12h = 12$ by 12 to find the value of $h$: $h = \\frac{12}{12} = 1$.\n",
            "\n",
            "\n",
            "Score: 0.7007 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "\n",
            "=== Step 7 ===\n",
            "\n",
            "Candidate (score 0.5947):\n",
            "$r^2 = 7^2 + h^2 \\Rightarrow r^2 = 7^2 + 1^2 \\Rightarrow r^2 = 49 + 1 \\Rightarrow r^2 = 50$\n",
            "\n",
            "\n",
            "Candidate (score 0.2186):\n",
            "Now that we have the value of $h$, we can substitute it into one of the original Pythagorean equations to solve for $r$: $r^2 = 7^2 + h^2 \\Rightarrow r^2 = 49 + 1 \\Rightarrow r^2 = 50$.\n",
            "\n",
            "#ANSWER: $\\boxed{\\sqrt{50} = 5\\sqrt{2}}$\n",
            "\n",
            "\n",
            "Candidate (score 0.7056):\n",
            "$r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = \\sqrt{25} \\cdot \\sqrt{2} = 5 \\sqrt{2}$\n",
            "\n",
            "\n",
            "Candidate (score 1.0000):\n",
            "Take the square root of both sides of the equation to solve for $r$: $r = \\sqrt{50}$.\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 1.0000 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "Take the square root of both sides of the equation to solve for $r$: $r = \\sqrt{50}$.\n",
            "\n",
            "\n",
            "Score: 0.7056 [IN PROGRESS]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "$r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = \\sqrt{25} \\cdot \\sqrt{2} = 5 \\sqrt{2}$\n",
            "\n",
            "\n",
            "=== Step 8 ===\n",
            "\n",
            "Candidate (score 0.4514):\n",
            "Simplify the square root by factoring out the perfect square: $r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = \\sqrt{25} \\cdot \\sqrt{2} = 5\\sqrt{2}$.\n",
            "#ANSWER: $5\\sqrt{2}$\n",
            "\n",
            "\n",
            "Candidate (score 1.0000):\n",
            "Simplify the square root to get $r$ in simplest form: $r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = 5 \\cdot \\sqrt{2}$.\n",
            "#ANSWER: $5 \\cdot \\sqrt{2}$.\n",
            "\n",
            "\n",
            "Candidate (score 0.5176):\n",
            "Since we found that $r = 5 \\sqrt{2}$, the next step is unnecessary, as the solution is already complete.\n",
            "\n",
            "#ANSWER: $5\\sqrt{2}$\n",
            "\n",
            "\n",
            "Candidate (score 0.3630):\n",
            "Since we already reached the final answer in the given solution, I'll just reformat the final answer according to the instructions.\n",
            "\n",
            "\n",
            "#ANSWER: $5 \\sqrt{2}$\n",
            "\n",
            "\n",
            "Selected for next beam:\n",
            "\n",
            "Score: 1.0000 [FINALIZED]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "Take the square root of both sides of the equation to solve for $r$: $r = \\sqrt{50}$.\n",
            "\n",
            "Simplify the square root to get $r$ in simplest form: $r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = 5 \\cdot \\sqrt{2}$.\n",
            "#ANSWER: $5 \\cdot \\sqrt{2}$.\n",
            "\n",
            "\n",
            "Score: 0.5176 [FINALIZED]\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "$r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = \\sqrt{25} \\cdot \\sqrt{2} = 5 \\sqrt{2}$\n",
            "\n",
            "Since we found that $r = 5 \\sqrt{2}$, the next step is unnecessary, as the solution is already complete.\n",
            "\n",
            "#ANSWER: $5\\sqrt{2}$\n",
            "\n",
            "\n",
            "=== Final Results ===\n",
            "\n",
            "Score: 1.0000\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "Take the square root of both sides of the equation to solve for $r$: $r = \\sqrt{50}$.\n",
            "\n",
            "Simplify the square root to get $r$ in simplest form: $r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = 5 \\cdot \\sqrt{2}$.\n",
            "#ANSWER: $5 \\cdot \\sqrt{2}$.\n",
            "\n",
            "\n",
            "Score: 0.5176\n",
            "Let $r$ be the radius of the circle, and draw a perpendicular line from the center of the circle to each of the two chords, which divides each chord into two equal parts: $7$ and $5$.\n",
            "$ANSWER:\n",
            "\n",
            "The perpendicular line from the center of the circle and the chords form two right triangles: $\\triangle COA$ and $\\triangle COB$. Let $h$ be the height of $\\triangle COA$ and $\\triangle COB$. Then, we can write two Pythagorean equations for these triangles: $r^2 = 7^2 + h^2$ and $r^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Set the two equations for $r^2$ equal to each other: $7^2 + h^2 = 5^2 + (h-6)^2$.\n",
            "\n",
            "Expand the equation $(h-6)^2$ and simplify: $49 + h^2 = 25 + (h^2 - 12h + 36)$.\n",
            "\n",
            "Combine like terms and simplify the equation to isolate $h$: $49 + h^2 = 25 + h^2 - 12h + 36 \\Rightarrow 49 = 61 - 12h$.\n",
            "\n",
            "Add $12h$ to both sides of the equation and subtract 61 from both sides to solve for $h$: $12h = 61 - 49 \\Rightarrow 12h = 12$.\n",
            "\n",
            "$h = 1 \\Rightarrow r^2 = 7^2 + h^2 = 49 + 1 = 50$\n",
            "\n",
            "$r = \\sqrt{50} = \\sqrt{25 \\cdot 2} = \\sqrt{25} \\cdot \\sqrt{2} = 5 \\sqrt{2}$\n",
            "\n",
            "Since we found that $r = 5 \\sqrt{2}$, the next step is unnecessary, as the solution is already complete.\n",
            "\n",
            "#ANSWER: $5\\sqrt{2}$\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice, Part 4: Confidence as a Synthetic PRM\n",
        "\n",
        "Training **Process Reward Models (PRMs)** is challenging, and only a few such models are available on Hugging Face—none of which are ideal. Therefore, having a **model-free** method for estimating solutions would be beneficial. One simple surrogate for process reward to consider is **confidence**.\n",
        "\n",
        "In the [LLM Inference Parameters notebook](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.6_llm_inference_parameters.ipynb), we discussed that LLMs exhibit varying levels of confidence in their generated outputs:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=12k5EFzMZAcHntuJZBZwbm6NKqJZ1OF3l\" width=600 />\n",
        "</center>\n",
        "\n",
        "The left image illustrates a case where the LLM is almost certain to generate \"LLM,\" while the right image shows a scenario where the model is less confident in its output. While uncertainty can be valuable in creative writing, it may indicate confusion - or even hallucinations - in mathematical problem-solving. Thus, for math and logical reasoning tasks, it is reasonable to assume that **solutions generated with higher confidence are more likely to be correct**.\n",
        "\n",
        "### Simple approach: using top predicted probability\n",
        "\n",
        "With this in mind, we suggest modifying the **Beam Search** algorithm to evaluate partial solutions based on their **mean confidence**. Confidence can be estimated using the **mean top predicted log probability**, calculated as:\n",
        "\n",
        "$$\\frac{1}{\\mathrm{n\\_steps}}\\sum_{i=1}^{\\mathrm{n\\_steps}}\\log\\left(\\mbox{Top token probability predicted at step $i$}\\right)$$\n",
        "\n",
        "The top probability can be obtained by calling `client.chat.completions.create` with `logprobs=True` and extracting `completion.choices[0].logprobs`.\n",
        "\n",
        "Although this approach is fairly simplistic, it may still be effective. A higher top probability implies lower probabilities for alternative tokens, indicating greater confidence in the top prediction.\n",
        "\n",
        "### A fancier approach: Negative Mean Entropy\n",
        "\n",
        "A more robust method involves using **negative mean entropy**. [Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) quantifies the uncertainty of a probability distribution. For next-token generation, it is calculated as:\n",
        "\n",
        "$$-\\sum_{w\\in\\mbox{Vocab}}\\widehat{p}_{w}\\log{ \\widehat{p}_{w} },$$\n",
        "\n",
        "where $\\widehat{p}_{w}$ represents the predicted probability of token $w$. Entropy behaves as follows:\n",
        "\n",
        "- $0$ when one token has a probability of 1 while all others have 0 (**absolute certainty**).\n",
        "- Maximum when all tokens have equal probabilities (**absolute uncertainty**).\n",
        "\n",
        "Thus, solutions with **lower entropy** are more confidently generated.\n",
        "\n",
        "Unfortunately, OpenAI's API only provides the top-5 token probabilities, limiting direct entropy calculation. However, entropy can still be estimated using these top-5 probabilities. So, you can also try this, but we recommend you to start with using only the top probability."
      ],
      "metadata": {
        "id": "HNoFHgvSF5em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR CODE HERE>"
      ],
      "metadata": {
        "id": "2zNj-_synPoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
